# 협업 필터링 추천 시스템

```python
# 1. 모든 사용자 간 평가의 유사도 계산
# 2. 추천 대상과 다른 사용자간 유사도 추출
# 3. 추천 대상이 평가하지 않은 아이템에 대한 예상 평가값 계산
#    평가값 = 다른 사용자 평가 X 다른 사용자 유사도
# 4. 아이템 중에서 예상 평가값 가장 높은 N개 추천

import os
import numpy as np
import pandas as pd

base_src = 'drive/MyDrive/Recosys/Data'

# user 데이터
u_user_src = os.path.join(base_src, 'u.user')
u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']
users = pd.read_csv(u_user_src, 
                    sep='|',
                    names=u_cols,
                    encoding='latin-1')
users = users.set_index('user_id')

# movie 데이터
u_item_src = os.path.join(base_src, 'u.item')
i_cols = ['movie_id', 'title', 'release date', 'video release date', 'IMDB URL',
          'unknown', 'Action', 'Adventure', 'Animation', 'Children\s', 'Comedy',
          'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',
          'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']
movies = pd.read_csv(u_item_src, 
                    sep='|',
                    names=i_cols,
                    encoding='latin-1')
movies = movies.set_index('movie_id')

# rating 데이터
u_data_src = os.path.join(base_src, 'u.data')
r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']
ratings = pd.read_csv(u_data_src, 
                    sep='\t',
                    names=r_cols,
                    encoding='latin-1')

# 정확도(RMSE)를 계산하는 함수
def RMSE(y_true, y_pred):
  return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))

# 모델별 RMSE를 계산하는 함수
def score(model):
  # 테스트 데이터의 user_id와 movie_id 간 pair를 맞춰 튜플형 원소 리스트 데이터를 만듦
  id_pairs = zip(x_test['user_id'],x_test['movie_id'])
  # 모든 사용자-영화 짝에 대해서 주어진 예측모델에 의해 예측값 계산 및 리스트형 데이터 생성
  y_pred = np.array([model(user,movie) for (user, movie) in id_pairs])
  # 실제 평점값
  y_true = np.array(x_test['rating'])
  return RMSE(y_true, y_pred)

# 데이터 셋 만들기
from sklearn.model_selection import train_test_split

x = ratings.copy()
y = ratings['user_id']
x_train,x_test,y_train,y_test = train_test_split(x,y,
                                                 test_size = 0.25,
                                                 stratify=y)
rating_matrix = x_train.pivot(index='user_id',
                              columns='movie_id',
                              values='rating')

# 코사인 유사도 계산
from sklearn.metrics.pairwise import cosine_similarity

# 코사인 유사도를 구하기 위해 rating 값을 복사하고, 계산 시 NaN 값 에러 대비를 위해 결측치를 0으로 대체
matrix_dummy = rating_matrix.copy().fillna(0)
# 모든 사용자간 코사인 유사도를 구함
user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)
# 필요한 값 조회를 위해 인덱스 및 컬럼명 지정
user_similarity = pd.DataFrame(user_similarity, 
                               index = rating_matrix.index,
                               columns = rating_matrix.index)

# 주어진 영화의(movie_id) 가중평균 rating을 계산하는 함수
def CF_simple(user_id, movie_id):
  if movie_id in rating_matrix.columns:
    sim_scores = user_similarity[user_id].copy()  # 해당 user의 다른 사용자들과의 유사도를 담음
    movie_ratings = rating_matrix[movie_id].copy()  # 해당 영화에 대한 다른 사람들의 평가
    none_rating_idx = movie_ratings[movie_ratings.isnull()].index  # 평가가 되어있지 않은(nan인) index(user_id)의 모음
    movie_ratings = movie_ratings.dropna()  # 평가안된 것들을 모두 없앰
    sim_scores = sim_scores.drop(none_rating_idx)  # 다른 사람들과의 유사도에서도 평가안한 사람들을 drop
    mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum()  # 주어진 영화에 대해서 평가한 다른 사람들과의 유사도 X 다른 사용자들의 평가 / 유사도 총합 을 하여 가중평균을 
    # https://m.blog.naver.com/hearimmind/220382137538 보고 이해를 해보자 

  else:
    mean_rating = 3.0
  return mean_rating

# 정확도 계산
score(CF_simple)
```



```python
# 이번에는 위의 방법에서 조금 개선해서 주어진 user와의 유사도가 비슷한 상위 k명에 대해서 계산하는 방법과(K Nearest Neighbors , KNN)
# 유사도에서 특정 값 이상인 것과 계산하는 방법을 살펴보겠다 (Thresholding 방법)
# 두 번째 방법이 조금 더 정확은 하나 만약 그 수치 값을 넘는 다른 user들의 양이 적을 수도 있기 때문에 KNN 방법도 고려를 해야한다.

# 유사집단의 크기를 미리 정하기 위해서 기존 score 함수에 neighbor_size 인자값 추가
def score(model, neighbor_size = 0 ):
  id_pairs = zip(x_test['user_id'],x_test['movie_id'])
  y_pred = np.array([model(user,movie, neighbor_size) for (user, movie) in id_pairs])
  y_true = np.array(x_test['rating'])
  return RMSE(y_true, y_pred)

from sklearn.model_selection import train_test_split

x = ratings.copy()
y = ratings['user_id']
x_train,x_test,y_train,y_test = train_test_split(x,y,
                                                 test_size = 0.25,
                                                 stratify=y)
rating_matrix = x_train.pivot(index='user_id',
                              columns='movie_id',
                              values='rating')


from sklearn.metrics.pairwise import cosine_similarity

matrix_dummy = rating_matrix.copy().fillna(0)
user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)
user_similarity = pd.DataFrame(user_similarity, 
                               index = rating_matrix.index,
                               columns = rating_matrix.index)

def CF_knn(user_id, movie_id, neighbor_size=0):
  if movie_id in rating_matrix.columns:
    sim_scores = user_similarity[user_id].copy()
    movie_ratings = rating_matrix[movie_id].copy()
    none_rating_idx = movie_ratings[movie_ratings.isnull()].index
    movie_ratings = movie_ratings.dropna()
    sim_scores = sim_scores.drop(none_rating_idx)

    if neighbor_size == 0:  # neighbor_size가 0이라면(default 값) 이전에 만들어둔 일반적인 CF로
      mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum()
    else:
      if len(sim_scores) > 1: # 1 보다는 커야 하니까
        neighbor_size = min(neighbor_size, len(sim_scores)) # neighbor_size가 sim_scores보다 크면 안되니 최소값으로 맞춰놓는 것임
        sim_scores = np.array(sim_scores)
        movie_ratings = np.array(movie_ratings)
        user_idx = np.argsort(sim_scores)  # np.argsort는 기본적으로 오름차순 정렬의 index 값을 돌려줌
        sim_scores = sim_scores[user_idx][-neighbor_size:] # -를 이용해 파이썬 배열을 뒤에서부터 size만큼 출력, 결국 sim_scores를 오름차순으로 정렬을 시키고 neighbor_size 만큼 뽑아온 것임
        movie_ratings = movie_ratings[user_idx][-neighbor_size:] # movie_rating도 마찬가지로 뽑아옴
        mean_rating = np.dot(sim_scores, movie_ratings) / sim_scores.sum() # 이들의 가중평균을 구함
      else:
        mean_rating = 3.0
  else:
    mean_rating = 3.0

  return mean_rating

score(CF_knn, neighbor_size=30)
```



```python
# 실제 주어진 사용자에 대한 추천을 받는 기능 구현
rating_matrix = ratings.pivot_table(index='user_id',	# 실제 추천이기 때문에 x_train말고 그냥 원본으로 pivot table 생성
                              columns='movie_id',
                              values='rating')
matrix_dummy = rating_matrix.copy().fillna(0)
user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)
user_similarity = pd.DataFrame(user_similarity, 
                               index = rating_matrix.index,
                               columns = rating_matrix.index)

def recom_movie(user_id, n_items, neighbor_size = 30):
  user_movie = rating_matrix.loc[user_id].copy()	# 특정 user의 movie 평가 뽑아옴

  for movie in rating_matrix.columns:
    if pd.notnull(user_movie.loc[movie]):	# null이 아닌 경우는 해당 user는 이미 해당 movie를 평가했다는 뜻이니(봤다는 뜻) 제외
      user_movie.loc[movie]= 0
    else:
      user_movie.loc[movie] = CF_knn(user_id, movie, neighbor_size) # 보지 않은거면 CF_knn으로 평점 예측
  
  movie_sort = user_movie.sort_values(ascending=False)[:n_items] # 평점으로 내림차순 후에 n_items 만큼 추출
  recom_movies = movies.loc[movie_sort.index] # movies에서 해당 추출 영화 뽑아오고
  recommendations = recom_movies['title'] # 제목 뽑아옴
  return recommendations

recom_movie(729, n_items = 5)
```



```python
# 사용자의 평가경향을 고려한 CF
# 사용자 A는 평균평점이 2.0이고 B는 평균평점이 4.0 이라면 두 사용자가 특정 영화에 3.0을 주었을 때 그 의미는 다를 것이다. 이를 고려한 CF
# 1. 각 사용자 평점평균 계산
# 2. 평점 -> 각 사용자의 평균에서의 차이로 변환 (평점 - 해당 사용자의 평점 평균)
# 3. 평점 편차의 예측값 계산 (평가값 = 평점편차 X 다른 사용자 유사도)
# 4. 실제 예측값 = 평점편차 예측값 + 평점평균

import os
import numpy as np
import pandas as pd

base_src = 'drive/MyDrive/Recosys/Data'

# user 데이터
u_user_src = os.path.join(base_src, 'u.user')
u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']
users = pd.read_csv(u_user_src, 
                    sep='|',
                    names=u_cols,
                    encoding='latin-1')
users = users.set_index('user_id')

# movie 데이터
u_item_src = os.path.join(base_src, 'u.item')
i_cols = ['movie_id', 'title', 'release date', 'video release date', 'IMDB URL',
          'unknown', 'Action', 'Adventure', 'Animation', 'Children\s', 'Comedy',
          'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',
          'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']
movies = pd.read_csv(u_item_src, 
                    sep='|',
                    names=i_cols,
                    encoding='latin-1')
movies = movies.set_index('movie_id')

# rating 데이터
u_data_src = os.path.join(base_src, 'u.data')
r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']
ratings = pd.read_csv(u_data_src, 
                    sep='\t',
                    names=r_cols,
                    encoding='latin-1')

# 정확도(RMSE)를 계산하는 함수
def RMSE(y_true, y_pred):
  return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))

# 모델별 RMSE를 계산하는 함수
def score(model, neighbor_size = 0):
  id_pairs = zip(x_test['user_id'],x_test['movie_id'])
  y_pred = np.array([model(user,movie, neighbor_size) for (user, movie) in id_pairs])
  y_true = np.array(x_test['rating'])
  return RMSE(y_true, y_pred)

# 데이터 셋 만들기
from sklearn.model_selection import train_test_split

x = ratings.copy()
y = ratings['user_id']
x_train,x_test,y_train,y_test = train_test_split(x,y,
                                                 test_size = 0.25,
                                                 stratify=y)
rating_matrix = x_train.pivot(index='user_id',
                              columns='movie_id',
                              values='rating')

matrix_dummy = rating_matrix.copy().fillna(0)
user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)
user_similarity = pd.DataFrame(user_similarity, 
                               index = rating_matrix.index,
                               columns = rating_matrix.index)

# 사용자 평가 경향을 고려한 함수
rating_mean = rating_matrix.mean(axis=1) # user의 평균평점을 구함
rating_bias = (rating_matrix.T - rating_mean).T # 평점 평균의 편차를 구함 T는 행렬을 전치해준 것인데 이렇게 해야 제대로 뺄셈이 됨, 한 번 따로 해보면 이해가능


# 사용자 평가 경향을 고려한 함수
def CF_knn_bias(user_id, movie_id, neighbor_size = 0):
  if movie_id in rating_bias.columns:
    sim_scores = user_similarity[user_id].copy()
    movie_ratings = rating_bias[movie_id].copy()  # 편차를 구하는 것이기 때문에 rating_bias에서 가져옴
    none_rating_idx = movie_ratings[movie_ratings.isnull()].index
    movie_ratings = movie_ratings.drop(none_rating_idx)
    sim_scores = sim_scores.drop(none_rating_idx)

    if neighbor_size == 0:
      prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum() # 일반적인 cf
      prediction = prediction + rating_mean[user_id] # 편차치를 구한 것이기 때문에 user의 평균값에 편차를 더해줌
    
    else:
      if len(sim_scores) > 1:
        neighbor_size = min(neighbor_size, len(sim_scores))
        sim_scores = np.array(sim_scores)
        movie_ratings = np.array(movie_ratings)
        user_idx = np.argsort(sim_scores)
        sim_scores = sim_scores[user_idx][-neighbor_size:]
        movie_ratings = movie_ratings[user_idx][-neighbor_size:]
        prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()
        prediction = prediction + rating_mean[user_id]

      else:
        prediction = rating_mean[user_id]	# 예외일 때에는 해당 user의 평균으로 넣어줌
  else:
    prediction = rating_mean[user_id]
    
  return prediction

score(CF_knn_bias, 30)
```



```python
# 사용자 A가 사용자 B와 C와의 유사도가 0.8로 같다고 하더라도 B와의 공통 평가 아이템이 2개이고, C와는 10개일 때 유사도의 신뢰도는 C가 더 높을 것이다.
# 이를 기반으로 유사도를 신뢰도에 따라서 가중을 하는 개념이다. 

import os
import numpy as np
import pandas as pd

base_src = 'drive/MyDrive/Recosys/Data'

# user 데이터
u_user_src = os.path.join(base_src, 'u.user')
u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']
users = pd.read_csv(u_user_src, 
                    sep='|',
                    names=u_cols,
                    encoding='latin-1')
users = users.set_index('user_id')

# movie 데이터
u_item_src = os.path.join(base_src, 'u.item')
i_cols = ['movie_id', 'title', 'release date', 'video release date', 'IMDB URL',
          'unknown', 'Action', 'Adventure', 'Animation', 'Children\s', 'Comedy',
          'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',
          'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']
movies = pd.read_csv(u_item_src, 
                    sep='|',
                    names=i_cols,
                    encoding='latin-1')
movies = movies.set_index('movie_id')

# rating 데이터
u_data_src = os.path.join(base_src, 'u.data')
r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']
ratings = pd.read_csv(u_data_src, 
                    sep='\t',
                    names=r_cols,
                    encoding='latin-1')

# 정확도(RMSE)를 계산하는 함수
def RMSE(y_true, y_pred):
  return np.sqrt(np.mean((np.array(y_true) - np.array(y_pred))**2))

# 모델별 RMSE를 계산하는 함수
def score(model, neighbor_size = 0):
  id_pairs = zip(x_test['user_id'],x_test['movie_id'])
  y_pred = np.array([model(user,movie, neighbor_size) for (user, movie) in id_pairs])
  y_true = np.array(x_test['rating'])
  return RMSE(y_true, y_pred)

# 데이터 셋 만들기
from sklearn.model_selection import train_test_split

x = ratings.copy()
y = ratings['user_id']
x_train,x_test,y_train,y_test = train_test_split(x,y,
                                                 test_size = 0.25,
                                                 stratify=y)
rating_matrix = x_train.pivot(index='user_id',
                              columns='movie_id',
                              values='rating')

from sklearn.metrics.pairwise import cosine_similarity
matrix_dummy = rating_matrix.copy().fillna(0)
user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)
user_similarity = pd.DataFrame(user_similarity, 
                               index = rating_matrix.index,
                               columns = rating_matrix.index)

# 사용자 평가 경향을 고려한 함수
rating_mean = rating_matrix.mean(axis=1)
rating_bias = (rating_matrix.T - rating_mean).T

rating_binary_1 = np.array(rating_matrix>0).astype(float)	# rating_matrix > 0 인 값을 array로 만든것임. NaN은 0으로 나머지는 1로된 array임
rating_binary_2 = rating_binary_1.T

counts = np.dot(rating_binary_1, rating_binary_2)  # a행렬 X a행렬 전치는 해당 user끼리 본 영화의 수를 나타낼 수 있음
# 예로 들어보면 
# ( 1 1 1 0          ( 1 0 1          ( 3 1 2
#   0 1 0 1      X     1 1 0      =     1 2 1
#   1 0 1 1 )          1 0 1            2 1 3 )        (n,n)은 본인자신이므로 본인이 본 모든 영화의 수, 나머지는 해당 user끼리
#                      0 1 1)                          겹치는 영화의 수인 것을 확인가능
counts = pd.DataFrame(counts, index = rating_matrix.index, columns = rating_matrix.index).fillna(0)
# 그것을 dataFrame으로 변환

def CF_knn_bias_sig(user_id, movie_id, neighbor_size = 0):
  if movie_id in rating_bias:
    sim_scores = user_similarity[user_id].copy()
    movie_ratings = rating_bias[movie_id].copy()

    no_rating = movie_ratings.isnull()		# movie_rating에서 null인지 여부를 뽑아냄
    common_counts = counts[user_id]		# 해당 user와 다른 user와의 영화공통 개수에 대한 정보를 뽑아냄
    low_significance = common_counts < SIG_LEVEL	# 지정한 SIG_LEVEL보다 낮은 사용자를 가려냄(공통 영화 수 적은 사람 필터링)
    none_rating_idx = movie_ratings[no_rating | low_significance].index # 아예 해당 영화 평가를 안했거나 위 필터에 걸린 index 뽑아냄
    
    movie_ratings = movie_ratings.drop(none_rating_idx) # drop 시켜주고
    sim_scores = sim_scores.drop(none_rating_idx) # 마찬가지로 유사도에서도 그 인원들 index drop

    if neighbor_size == 0:
      prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()
      prediction = prediction + rating_mean[user_id]

    else:
      if len(sim_scores) > MIN_RATINGS: # 현재 해당 영화를 평가한 사용자 수가 MIN_RATINGS의 수보다 큰 경우에만 계산을 하겠다는 뜻
        neighbor_size = min(neighbor_size, len(sim_scores))
        sim_scores = np.array(sim_scores)
        movie_ratings = np.array(movie_ratings)
        user_idx = np.argsort(sim_scores)
        sim_scores = sim_scores[user_idx][-neighbor_size:]
        movie_ratings = movie_ratings[user_idx][-neighbor_size:]
        prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()
        prediction = prediction + rating_mean[user_id]
      
      else:
        prediction = rating_mean[user_id]
  
  else:
    prediction = rating_mean[user_id]
  
  return prediction

SIG_LEVEL = 3
MIN_RATINGS = 3
score(CF_knn_bias_sig, 30)
```



```python
# 아이템 기반 CF(Item Based CF)

def score(model):
  id_pairs = zip(x_test['user_id'],x_test['movie_id'])
  y_pred = np.array([model(user,movie) for (user, movie) in id_pairs])
  y_true = np.array(x_test['rating'])
  return RMSE(y_true, y_pred)


rating_matrix_t = np.transpose(rating_matrix)		# 전치를 해서 밑에서 similarity 계산할 때 movie_id끼리의 유사도로 돌게함

matrix_dummy = rating_matrix_t.copy().fillna(0)

item_similarity = cosine_similarity(matrix_dummy, matrix_dummy)
item_similarity = pd.DataFrame(item_similarity, 
                               index = rating_matrix_t.index,
                               columns=rating_matrix_t.index)

def CF_IBCF(user_id, movie_id):
  if movie_id in item_similarity.columns:
    sim_scores = item_similarity[movie_id]
    user_rating = rating_matrix_t[user_id]
    none_rating_idx = user_rating[user_rating.isnull()].index
    user_rating = user_rating.dropna()
    sim_scores = sim_scores.drop(none_rating_idx)
    mean_rating = np.dot(sim_scores, user_rating) / sim_scores.sum()
  
  else:
    mean_rating = 3.0
  
  return mean_rating

score(CF_IBCF)
```

---

