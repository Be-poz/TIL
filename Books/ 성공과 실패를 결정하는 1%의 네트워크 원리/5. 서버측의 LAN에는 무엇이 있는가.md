# 서버측의 LAN에는 무엇이 있는가?

## 웹 서버의 설치 장소

### 사내에 웹 서버를 설치하는 경우

패킷이 가장 가까운 라우터, 액세스 회선, 서버측 라우터를 경유할 수도 있지만 현재는 방화벽을 두는 방법이 일반적이다. 방화벽은 특정 서버에서 동작하는 특정 애플리케이션에 액세스하는 패킷만 통과시키고, 그 외의 패킷을 차단하는 역할을 한다. 그러나 액세스를 허가한 애플리케이션에 보안 구멍이 있으면 공격받을 위험성이 남아있기 때문에 위험성이 완전히 없어진 것은 아니다.  

### 데이터센터에 웹 서버를 설치하는 경우

회사 안에 웹 서버를 설치하는 경우가 아닌, 프로바이더 등이 운영하는 데이터센터라는 시설에 서버를 가지고 들어가서 설치하거나 프로바이더가 소유하는 서버를 빌려쓰는 형태로 운영하는 경우도 있다. 데이터센터는 내진 구조의 건물에 설치하거나, 자가 발전 장치를 비치하거나, 24시간 입퇴실이 관리되는 곳이 많으므로 회사 안보다는 안전성이 높다.  

웹 서버가 데이터센터에 설치된 경우에는 인터넷의 중심 부분에서 데이터센터로 패킷이 흘러가고, 여기에서 서버 머신에 도착한다. 어느 경우든지 패킷은 라우터에서 중계되고 최종적으로 서버에 도착한다는 점은 달라지지 않는다.  

<br/>

## 방화벽의 원리와 동작

### 패킷 필터링형이 주류이다

패킷 선별 작업에 다양한 방법이 고안되었으나 여러 이유로 현재는 패킷 필터링형이 가장 많이 보급되었다.  

### 패킷 필터링의 조건 설정 개념

수신처 IP 주소와 송신처 IP 주소에 따라 시점과 종점을 판단한다. 흐름의 종점은 웹 서버가 되므로 이것을 조건으로 설정하고 조건에 해당하는 패킷만 통과시킨다.  

웹 서버에서 인터넷측으로 흐르는 패킷도 있을 것이다. 이 패킷도 웹 서버에서 인터넷측으로 흘러간 후 그곳에서 시점이 웹 서버의 주소에 일치하는 패킷도 통과한다. 이와 같이 수신처나 송신처의 주소에 따라 패킷이 어디서, 어디로 흘러가는지를 판단하여 통과시킬 것인지, 차단할 것인지 결정하는 것이 첫걸음이다.  

### 애플리케이션을 한정할 때 포트 번호를 사용한다

애플리케이션을 한정할 때는 TCP 헤더나 UDP 헤더에 기록되어있는 포트 번호를 조건으로 추가한다. 웹 서버의 포트 번호는 80번으로 결정되어 있으므로 전술한 수신처 IP 주소 및 송신처 IP 주소에 수신처 포트 번호가 80번인 경우에 대한 조건도 추가한다.  

### 컨트롤 비트로 접속 방향을 판단한다

허가하는 액세스 동작에서 흐르는 패킷과 그 외의 패킷을 완전히 선별할 수 있을 때까지 조건을 추가한다. 그리고 액세스를 허가하는 패킷만 통과시키고, 그 외는 차단하도록 조건을 설정한다.  

### 사내 LAN에서 공개 서버용 LAN으로 조건을 설정한다

### 밖에서 사내 LAN으로 액세스할 수 없다

주소 변환을 이용하면 당연히 인터넷측에서 사내 LAN에는 액세스할 수 없게 된다. 따라서 사내 LAN에 대한 액세스를 금지하도록 패킷 필터링의 조건을 설정할 필요가 없다.  

### 방화벽을 통과한다

패킷이 도착하면 통과/차단 여부를 판정한 후 차단하는 대상이 되면 패킷을 버리고, 버린 기록을 남긴다. 이는 버린 패킷 중에 부정 침입의 흔적을 나타내는 것이 있으므로 이것을 분석하여 침입자의 수법을 밝히거나 향후 부정 침입 대책에 도움이 될 수 있기 때문이다. 일단 통과시킨다고 결정되면 그 이상의 특별한 구조는 없다.  

### 방화벽으로 막을 수 없는 공격

웹 서버에 좋지 않은 상태가 있어서 특수한 데이터를 포함한 패킷을 받으면 웹 서버가 다운된다는 상황이 있다. 방화벽은 시점과 종점만 조사하므로 패킷 중에 특수한 데이터가 포함되어 있어도 이것에 신경쓰지 않고 패킷을 통과시켜 버린다. 그러면 이 패킷이 웹 서버에 도착하면 웹 서버는 다운된다.  

이러한 상황에는 두 가지의 대처법이 있다. 이 문제의 원인은 웹 서버 소프트웨어의 버그에 있으므로 버그를 고쳐서 다운되지 않도록 하는 것이 한 가지 대처법이다. 또 한 가지 방법은 패킷의 내용을 조사하여 위험한 데이터가 포함되어 있는 경우에 패킷을 차단하도록 장치나 소프트웨어를 방화벽과는 별도로 준비하는 방법이다.  

<br/>

## 복수 서버에 리퀘스트를 분배한 서버의 부하 분산

### 처리 능력이 부족하면 복수 서버로 부하 분산된다

복수 서버를 두었을 때의 결점은 다음과 같다. 웹 서버가 많으면 이 중에서 고장나는 것도 있을 것이다. 이때 고장난 웹 서버를 피해서 IP 주소를 회답하면 좋지만, 보통의 DNS 서버는 웹 서버가 동작하지 않는지 확인하지 못하므로 웹 서버가 정지해도 상관하지 않고 IP 주소를 회답해 버린다.  

그리고 라운드 로빈에서 차례대로 웹 서버를 분배하면 좋지 않은 상태가 생길 수도 있는데, 복수의 페이지에 걸쳐 대화하는 도중 웹 서버가 변하면 대화가 도중에 끊길 수 있기 때문이다.  

### 부하 분산 장치를 이용해 복수의 웹 서버로 분할된다

이러한 좋지 않은 상태를 피하기 위해 부하 분산 장치 또는 로드 밸런서 등으로 부르는 기기가 고안됐다. 이를 사용할 때 먼저 부하 분산 장치를 웹 서버 대신 DNS 서버에 등록한다. 이 기기가 어느 웹 서버에 리퀘스트를 전송해야 할지 판단을 해야하는데, 대화가 복수의 페이지에 걸쳐있는지에 따라 판단 기준이 전혀 다르다. 복수 페이지에 걸쳐있지 않은 단순한 액세스라면 웹 서버의 부하 상태가 판단 근거가 될 것이다. 부하는 단시간에 증가하거나 감소하므로 꼼꼼히 상황을 조사하지 않으면 정확한 곳까지 파악할 수 없다. 그렇다고 너무 자세한 상황을 조사하려면 부하를 조사하는 동작 자체로 웹 서버의 부하가 증가해 버린다. 아무튼 특정 웹 서버에 부하가 집중되지 않도록 한다는 점은 모든 방법에 공통이 된다.  

대화가 복수 페이지에 걸쳐있을 때는 웹 서버의 부하에 관계 업싱 이전의 리퀘스트와 같은 웹 서버에 전송해야 한다. 전후 관계를 판단하기 위해 여러 가지 방법이 고안되었다. 양식에 입력한 데이터를 보낼 때 그 안에 전후의 관련을 나타내는 정보를 부가하거나 HTTP의 사양을 확장하여 전후 관계를 판단하기 위한 정보를 HTTP헤더 필드에 부가하는 방법이다. 부하 분산 장치는 이러한 정보를 조사하여 일련의 동작이라면 이전과 같은 웹 서버에 리퀘스트를 전송하고, 그렇지 않으면 부하가 적은 웹 서버에 전송하도록 동작한다.  

<br/>

## 캐시 서버를 이용한 서버의 부하 분산

