# 스쿱

아파치 스쿱은 구조화된 데이터 저장소에서 데이터를 추출해서 하둡으로 보내 처리할 수 있도록 해주는 오픈 소스 도구다.  
이러한 처리는 맵리듀스 프로그램이나 하이브 같은 다른 고차원 도구로도 할 수 있다.  
또한 관계형 데이터베이스의 데이터를 HBase로 옮기는 데 스쿱을 사용할 수 있다.  

<br/>

## 스쿱 커넥터

스쿱은 대용량 데이터 전송 기능이 있는 외부 저장 시스템에 데이터를 임포트하고 익스포트하는 확장 프레임워크다.  
스쿱 커넥터는 이 프레임워크를 사용하여 스쿱이 임포트와 익스포트하게 해주는 모듈식 컴포넌트다.  

스쿱은 다양한 관계형 데이터베이스에서 작동하는 커넥터를 제공한다.  

<br/>

## 임포트 예제

<img width="458" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/fc00f545-e5e0-4602-a413-d87ebfbc844c">

위와 같이 widgets라는 테이블에 3개의 row를 넣어놨다.  

MYSQL용 JDBC 드라이버 JAR 파일(Connector/J)을 내려받고, 이를 스쿱의 lib 디렉터리에 저장한다.  

``sqoop import --connect jdbc:mysql://localhost:3306/sqoop --table widgets -m 1``  

명령어로 임포트 시켰다(하나의 맵 태스크만 사용함).  

```
% hadoop fs -cat widgets/part-m-00000
1,sprocket,0.25,2023-11-19,1,Connects tow gizmos
2,gadget,99.99,2021-22-19,13,Our flagship product
3,gizmo,4.00,2022-11-19,4,null
```

스쿱은 텍스트 파일 외에 다른 파일 포맷으로도 임포트한 데이터를 저장할 수 있다.  

<br/>

## 생성된 코드

데이터베이스 테이블의 내용을 HDFS에 저장하는 것 외에도 스쿱은 로컬 디렉터리에 자바 소스 파일을 생성한다.  

``sqoop codegen --connect jdbc:mysql://localhost:3306/sqoop --table widgets --class-name Widget``  

codegen은 전체 임포트를 하지 않고 단순히 코드만 생성한다. 임포트한 레코드를 시퀀스 파일에 저장하려면 반드시 생성된 클래스를 사용해야 한다. 텍스트 파일 기반의 레코드를 다룰 때는 생성된 코드를 사용하지 않아도 된다.  

<br/>

## 임포트 자세히 살펴보기

<img width="707" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/c2fee8a6-7ed8-4c0e-95e8-2579c7fc3599">

스쿱도 하둡처럼 자바로 작성되었다. 자바의 JDBC API를 이용한다. 대부분의 데이터베이스 벤더는 JDBC API를 제공하고 자사의 데이터베이스 서버에 접속하는 데 필요한 코드가 포함된 JDBC 드라이버를 제공한다.  

스쿱은 임포트를 시작하기 전에 JDBC로 임포트 대상 테이블을 검사하며, 모든 컬럼의 목록과  SQL 데이터 타입을 추출한다.  
그리고 SQL 데이터 타입을 맵리듀스 애플리케이션의 필드에 적용될 자바 자료형으로 매핑한다. 스쿱의 코드 생성기는 이 정보를 이용하여 테이블에서 추출한 레코드에 적용할 테이블 특화 클래스를 생성한다.  

![image](https://github.com/Be-poz/TIL/assets/45073750/59d35863-4e80-4845-a8df-76decdb73f2d)

JDBC의 ResultSet ㅣㄴ터페이스는 쿼리에서 레코드를 하나씩 추출하는 커서를 제공한다.  
``readFields()`` 메서드는 ResultSet 데이터의 한 행에 있는 컬럼을 읽어서 Widget 객체의 필드 값을 채운다.  
스쿱은 ``write()`` 메서드로 새로운  Widget 행을 테이블에 추가하며 이러한 과정을 익스포팅이라고 한다.  

분할 기준 컬럼이 또 중요한데, 테이블에 기본 키가 있으면 이 컬럼을 분할 기준 컬럼으로 사용한다.  
기본 키 컬럼의 최댓값과 최솟값을 조회한 후 태스크 수를 기준으로 각 맵 태스크가 수행할 쿼리를 정한다.  

<br/>

### 증분 임포트

HDFS 데이터와 데이터베이스의 데이터의 동기화를 유지하기 위해 주기적으로 임포트 작업을 수행하는데,  
``--check-column``으로 지정한 컬럼의 특정 값보다 큰 행을 임포트하는 기능을 제공한다.  

``--last-value`` 인자로 지정한 값은 계속 증가하는 행의 ID와 같다. auto_increment로 지정한 기본 키 컬럼이 좋은 예다.  

이런 방식은 데이터베이스 테이블에 새로운 행이 계속 추가되지만 기존 행의 값이 변경되지 않을 때 적합하다.  
이런 모드를 **추가 모드** 라고 하며 ``--incremental append`` 옵션을 지정하여 사용할 수 있다. 다른 옵션은 시간을 기반으로 증분 임포트(``--incremental lastmodified``)를 수행하는 것으로 기존 행의 값이 변경될 수 있고 해당 레코드에 최종 수정 시간을 기록하는 컬럼이 있을 때 적합한 방식이다.  

증분 임포트를 실행하면 스쿱은 출력의 마지막 부분에 다음 임포트에서 ``--last-value``로 지정할 값을 보여준다. 물론 이 값은 증분 임포트를 수동으로 수행할 때 유용하며, 주기적으로 임포트를 실행할 때는 스쿱의 잡 저장 기능을 활용하는 것이 좋다.  
이 기능은 마지막 값을 자동으로 저장하고 다음 잡을 수행할 때 그 값을 이용한다.  

<br/>

### 직접 모드 임포트

일부 데이터베이스는 데이터를 매우 빨리 추출할 수 있는 특정 도구를 제공하기도 한다. 예를 들어 MYSQL의 mysqldump 애플리케이션은 JDBC 채널보다 훨씬 빨리 테이블을 읽을 수 있다.  

직접 모드는 JDBC 방식과 같은 범용이 아니기 때문에 사용자가 직접 ``--direct`` 인자로 지정해주어야 한다.  

데이터베이스의 내용에 접근하는 데 직접 모드를 사용하더라도 메타데이터 정보는 JDBC를 통해 조회된다.  

<br/>

## 대용량 객체 임포트하기

![image-20231119204306100](/Users/user/Library/Application Support/typora-user-images/image-20231119204306100.png)

대부분의 데이터베이스는 단일 필드에 대용량 데이터를 저장하는 기능을 제공한다. 이런 데이터가텍스트인지 바이너리인지에 따라서 데이터베이스 테이블에서 CLOB 또는 BLOB 컬럼으로 표현된다.  

대용량 객체는 보통 데이터베이스 자체적으로 특별한 방식으로 처리된다. 인라인 형태로 저장된다면 스캔 성능에 심각한 영향을 끼칠 것이기 때문에 대용량 객체는 행 외부에 저장된다. 대용량 객체를 접근할 때 행에 포함된 참조값을 따라 객체를 여는 과정이 추가로 필요하다.  

데이터베이스처럼 맵리듀스는 모든 레코드를 매퍼로 보내기 전에 실체화한다. 그런데 개별 레코드가 너무 크면 비효율적일 수 있다. 스쿱으로 불러온 레코드는 데이터베이스의 내부 구조와 유사하게 디스크에 배치된다. 즉, 레코드의 모든 필드는 사슬처럼 이어진 일종의 레코드의 배열로 저장된다. 맵리듀스 프로그램이 불러온 레코드를 처리할 때 각 맵 태스크는 입력 스플릿의 각 레코드의 모든 필드를 완전히 실체화해야 한다.  

하지만 대용량 객체의 크기가 너무 크면 메모리에 실체화하는 것이 불가능할 수 있다. 따라서 LobFile이라고 하는 별도의 파일에 저장한다. 

<br/>

## 익스포트 수행하기

익스포트는 데이터 소스로는 HDFS를, 목적지로는 원격 데이터베이스를 사용한다.  

``sqoop export --connect jdbc:mysql://localhost:3306/sqoop -m 1 --table destination --export-dir /user/hive/warehouse/source --input-fields-terminated-by '\1001'``  

![image-20231119205908502](/Users/user/Library/Application Support/typora-user-images/image-20231119205908502.png)

---

