# 맵리듀스 프로그래밍

```xml
// configuration-1.xml
<?xml version="1.0"?>
<configuration>
  <property>
    <name>color</name>
    <value>yellow</value>
      <description>Color</description>
  </property>
  <property>
    <name>weight</name>
    <value>heavy</value>
    <final>true</final>
    <description>Weight</description>
  </property>
  <property>
    <name>size</name>
    <value>10</value>
    <description>Size</description>
  </property>
  <property>
    <name>size-weight</name>
    <value>${size}, ${weight}</value>
    <description>Size and Weight</description>
  </property>
</configuration>

//configuration-2.xml
<?xml version="1.0"?>
<configuration>
  <property>
    <name>size</name>
    <value>12</value>
    <description>Size</description>
  </property>
  <property>
    <name>weight</name>
    <value>heavy</value>
    <description>Light</description>
  </property>
</configuration>
```

```java
import org.apache.hadoop.conf.Configuration;

Configuration conf = new Configuration();
conf.addResource("configuration-1.xml");
assertThat(conf.get("color")).isEqualTo("yellow");
assertThat(conf.get("size")).isEqualTo("10");
assertThat(conf.getInt("size", 0)).isEqualTo(10);
assertThat(conf.get("weight")).isEqualTo("heavy");
assertThat(conf.get("size-weight")).isEqualTo("10, heavy");

conf.addResource("configuration-2.xml");
assertThat(conf.get("weight")).isEqualTo("heavy");
assertThat(conf.get("size")).isEqualTo("12");
```

``org.apache.hadoop.conf`` 아래에 있는 ``Configuration`` 클래스 인스턴스를 이용하여 XML 파일로부터 속성 정보를 읽을 수 있다. 여러 리소스를 읽을 때에는 이전에 정의된 속성을 오버라이드한다. final이 true면 오버라이드 되지 않는다.  

<Br/>

```java
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;

public class ConfigurationPrinter extends Configured implements Tool {

    static {
        Configuration.addDefaultResource("hdfs-default.xml");
        Configuration.addDefaultResource("hdfs-site.xml");
        Configuration.addDefaultResource("yarn-default.xml");
        Configuration.addDefaultResource("yarn-site.xml");
        Configuration.addDefaultResource("mapred-default.xml");
        Configuration.addDefaultResource("mapred-site.xml");
    }

    @Override
    public int run(String[] args) throws Exception {
        Configuration conf = getConf();
        for (Entry<String, String> entry : conf) {
            System.out.printf("%s=%s\n", entry.getKey(), entry.getValue());
        }
        return 0;
    }

    public static void main(String[] args) throws Exception {
        int exitCode = ToolRunner.run(new ConfigurationPrinter(), args);
        System.out.println(exitCode);
    }
}
```

하둡은 명령행에서 잡을 쉽게 실행할 수 있도록 몇 가지 헬퍼 클래스를 제공한다.  

Configurable 인터페이스를 구현한 Configured 클래스를 상속받아 ConfigurationPrinter를 만든다.  
Configured 클래스를 상속받으면 Tool 인터페이스의 부모인  Configurable 인터페이스를 쉽게 구현할 수 있다.  
run() 메서드는 Configurable의 getConf() 메서드를 통해 Configuration 객체를 반복적으로 얻고 모든 속성을 표준 출력으로 출력한다.  

<br/>

```java
import java.io.IOException;
import org.apache.hadoop.io.*;
import org.apache.hadoop.mapreduce.Mapper;

public class MaxTemperatureMapper extends Mapper<LongWritable, Text, Text, IntWritable> {
  
  @Override
  public void map(LongWritable key, Text value, Context context)
      throws IOException, InterruptedException {
    
    String line = value.toString();
    String year = line.substring(15, 19);
    int airTemperature = Integer.parseInt(line.substring(87, 92));
    context.write(new Text(year), new IntWritable(airTemperature));
  }
}
```

```java
public class MaxTemperatureMapperTest {

  @Test
  public void processesValidRecord() throws IOException, InterruptedException {
    Text value = new Text("0043011990999991950051518004+68750+023550FM-12+0382" +
                                  // Year ^^^^
        "99999V0203201N00261220001CN9999999N9-00111+99999999999");
                              // Temperature ^^^^^
    new MapDriver<LongWritable, Text, Text, IntWritable>()
      .withMapper(new MaxTemperatureMapper())
      .withInput(new LongWritable(0), value)
      .withOutput(new Text("1950"), new IntWritable(-11))
      .runTest();
  }
}
```

위와 같이  ``MapDriver``를 이용해서 Mapper 테스트가 가능하다.  

```java
public class MaxTemperatureReducer
  extends Reducer<Text, IntWritable, Text, IntWritable> {

  @Override
  public void reduce(Text key, Iterable<IntWritable> values,
      Context context)
      throws IOException, InterruptedException {
    
    int maxValue = Integer.MIN_VALUE;
    for (IntWritable value : values) {
      maxValue = Math.max(maxValue, value.get());
    }
    context.write(key, new IntWritable(maxValue));
  }
}
```

```java
public class MaxTemperatureReducerTest {
  
  @Test
  public void returnsMaximumIntegerInValues() throws IOException,
      InterruptedException {
    new ReduceDriver<Text, IntWritable, Text, IntWritable>()
      .withReducer(new MaxTemperatureReducer())
      .withInput(new Text("1950"),
          Arrays.asList(new IntWritable(10), new IntWritable(5)))
      .withOutput(new Text("1950"), new IntWritable(10))
      .runTest();
  }
}
```

Reducer 또한 테스트가 가능하다.  

<br/>

## 로컬에서 실행하기

```java
public class MaxTemperatureDriver extends Configured implements Tool {

  @Override
  public int run(String[] args) throws Exception {
    if (args.length != 2) {
      System.err.printf("Usage: %s [generic options] <input> <output>\n",
          getClass().getSimpleName());
      ToolRunner.printGenericCommandUsage(System.err);
      return -1;
    }
    
    Job job = new Job(getConf(), "Max temperature");
    job.setJarByClass(getClass());

    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
    
    job.setMapperClass(MaxTemperatureMapper.class);
    job.setCombinerClass(MaxTemperatureReducer.class);
    job.setReducerClass(MaxTemperatureReducer.class);

    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);
    
    return job.waitForCompletion(true) ? 0 : 1;
  }
  
  public static void main(String[] args) throws Exception {
    int exitCode = ToolRunner.run(new MaxTemperatureDriver(), args);
    System.exit(exitCode);
  }
}
```

Tool 인터페이스를 활용해서 연도별 최대 기온을 찾는 맵리듀스 잡을 실행하는 드라이버를 작성할 수 있다.  

```shell
mvn compile
export HADOOP_CLASSPATH=target/classes/
hadoop v2.MaxTemperatureDriver -fs file:/// -jt local input/ncdc/micro output
```

<img width="253" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/874fec50-976e-4aa8-af5b-3e542fe00189">

```shell
 hadoop jar target/ch06-mr-dev-4.0.jar  v2.MaxTemperatureDriver -fs file:/// -jt local input/ncdc/micro output
```

위와 같이 jar 파일을 이용할 수도 있다.  

```shell
hadoop v2.MaxTemperatureDriver /user/bepoz/sample.txt /user/bepoz/result
```

hdfs에 파일을 넣고 위와 같이 실행할 수도 있다.  

<br/>

### 잡 디버깅

```java
public class MaxTemperatureMapper
  extends Mapper<LongWritable, Text, Text, IntWritable> {

  /*[*/enum Temperature {
    OVER_100
  }/*]*/
  
  private NcdcRecordParser parser = new NcdcRecordParser();

  @Override
  public void map(LongWritable key, Text value, Context context)
      throws IOException, InterruptedException {
    
    parser.parse(value);
    if (parser.isValidTemperature()) {
      int airTemperature = parser.getAirTemperature();
      /*[*/if (airTemperature > 1000) {
        System.err.println("Temperature over 100 degrees for input: " + value);
        context.setStatus("Detected possibly corrupt record: see logs.");
        context.getCounter(Temperature.OVER_100).increment(1);
      }/*]*/
      context.write(new Text(parser.getYear()), new IntWritable(airTemperature));
    }
  }
}
```

위와 같은 방법으로 로그/상태/카운터를 남겨 의심스러운 입력 레코드를 확인할 수 있다.  

```shell
mapred job -counter {job_id} '{패키지를 포함한 전체 클래스명}' {카운터 이름(enum 이름)}
```

위와 같은 방식으로 카운터의 값을 확인할 수 있다(웹  UI도 가능).  

```java
  @Test
  public void parsesMalformedTemperature() throws IOException,
      InterruptedException {
    Text value = new Text("0335999999433181957042302005+37950+139117SAO  +0004" +
                                  // Year ^^^^
        "RJSN V02011359003150070356999999433201957010100005+353");
                              // Temperature ^^^^^
    Counters counters = new Counters();
    new MapDriver<LongWritable, Text, Text, IntWritable>()
      .withMapper(new MaxTemperatureMapper())
      .withInput(new LongWritable(0), value)
      .withCounters(counters)
      .runTest();
    Counter c = counters.findCounter(MaxTemperatureMapper.Temperature.MALFORMED);
    assertThat(c.getValue(), is(1L));
  }
```

위와 같은 테스트 코드로도 확인 가능하다.  

<br/>

하둡은 다양한 사용자를 위해 여러 장소에 로그를 생성한다.  

* 시스템 데몬 로그
  * 관리자가 사용
  * 각 하둡 데몬은 로그파일(lof4j 이용)과 표준 출력과 에러를 결합한 파일을 생성한다. 이는  HADOOP_LOG_DIR 환경변수에 저장한 디렉터리에 쓰인다.
* HDFS 감사 로그
  * 사용자가 사용
  * HDFS와 관련된 모든 요청에 대한 로그로, 기본적으로 사용하지 않는다. 무엇으로 설정되든 네임노드 로그에 쓰인다.
* 맵리듀스 잡 히스토리 로그
  * 사용자가 사용
  * 잡을 실행하는 과정에 발생하는 이벤트 로그다. HDFS 내의 한 곳에 모아서 저장된다.
* 맵리듀스 태스크 로그
  * 사용자가 사용
  * 각 태스크 자식 프로세스는 는  log4j를 사용하는 로그파일, 표준 출력으로 보낸 데이터 파일, 표준 에러를 위한 파일을 생성한다. 이는  YARN_LOG_DIR 환경변수에 지정한 디렉터리의  userlogs 서브디렉터리에 쓰인다.

<br/>

## 잡 튜닝하기

* 매퍼 수
  * 매퍼가 얼마나 오랫동안 수행되고 있는가? 만약 평균 몇 초 내로 수행된다면 더 적은 수의 매퍼로 더 오래 실행할 수 있는 방법이 있는지 확인
* 리듀서 수
  * 두 개 이상의 리듀서를 사용 중인지 확인. 리듀스 태스크는 경험상 5분 내외로 실행되며 최소 하나의 의미 있는 데이터 블록을 생성하길 권장
* 컴바이너
  * 셔플을 통해 보내지는 데이터양을 줄이기 위해 컴바이너를 활용할 수 있는지 확인
* 중간 데이터 압축
  * 맵 출력을 압축하면 잡 실행 시간을 거의 대부분 줄일 수 있다
* 커스텀 직렬화
  * 커스텀  Writable 객체나 Comparator를 사용하고 있다면 RawComparator를 구현했는지 반드시 확인
* 셔플 튜닝
  * 맵리듀스 셔플은 메모리 관리를 위해 대략 12개 정도의 튜닝 인자를 제공하는데, 이는 성능을 조금이라도 향상시키는 데 도움을 줄 수 있다

  

잡은 복잡하게 만들기보다는 더 많이 만드는 것이 좋다. 세밀하게 나누는 것이 좋다는 뜻이다.  

---

