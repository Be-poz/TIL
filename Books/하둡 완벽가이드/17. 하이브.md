# 하이브

하이브는 HDFS에 저장된 대량의 데이터를 분석할 수 있도록 개발되었다.  

하이브는 HDFS에 저장된 데이터에 구조(스키마)를 입히는 방식으로 데이터를 테이블로 구조화시킨다.  
테이블 스키마와 같은 메타데이터는 메타스토어라 불리는 데이터베이스에 저장된다.  

```shell
hive -f script.q		# 지정한 파일에 대해서만 hive 명령어가 실행

hive -e 'SELECT * FROM dummy'		# -e 옵션을 이용하여 명령행에 직접 입력

hive -S -e 'SELECT * FROM dummy'		# -S 옵션을 이용하여 불필요한 메시지의 출력을 막아 출력 결과만 봄
```

![image-20231121000221399](/Users/user/Library/Application Support/typora-user-images/image-20231121000221399.png)

![image-20231121000314671](/Users/user/Library/Application Support/typora-user-images/image-20231121000314671.png)

메타스토어는 하이브 메타데이터의 핵심 저장소다.  
기본적으로 메타데이터 서비스는 하이브 서비스와 동이한 JVM에서 실행되고 로컬 디스크에 저잦ㅇ되는 내장형 더비 데이터베이스 인스턴스를 포함한다.  

내장형 더비 데이터베이스 인스턴스는 한 번에 디스크에 위치한 데이터베이스 파일 하나에만 접근할 수 있다. 이것은 사용자가 동일한 메타스토어를 공유하는 그 순간에 단 하나의 하이브 세션만 사용할 수 있다는 의미다. 두 번째 세션을 시작하면 메타스토어와의 연결을 얻기 위한 시도는 실패하고 에러가 발생한다.  

다중 세션을 위해서는 로컬 메타스토어 방식을 사용해야 한다. 메타스토어 서비스는 하이브 서비스와 동일한 프로세스에서 실행되지만 동일 머신이나 원격 머신에서 별도의 프로세스로 실행되는 데이터베이스와 연결할 수 있다.  

원격 메타스토어라 불리는 다른 메타스토어 설정이 있는데, 하나 이상의 메타스토어 서버가 하이브 서비스와는 별도의 프로세스로 실행된다. 원격 메타스토어를 설정해두면 데이터베이스 계층이 방화벽의 역할을 대신하고, 따라서 클라이언트는 데이터베이스 자격 증명을 더 이상 얻을 필요가 없기 때문에 관리성과 보안성이 더 높아진다.  

<br/>

## 전통적인 DB와의 비교

하이브는 전통적인 DB와 여러면에서 비슷하지만 하이브는 HDFS와 맵리듀스를 기반으로 개발되었다.  

전통적인 DB에서 테이블의 스키마는 데이터를 로드하는 시점에 검증된다. 만일 로드중인 데이터가 스키마에 부합되지 않으면 해당 데이터를 거부한다. 이러한 설계 방식을 쓰기 스키마라고 부른다. DB에 쓰는 시점에 데이터의 스키마를 검증하기 때문이다.  

하이브는 로드 시점이 아니라 쿼리를 실행할 때 그 데이터를 검증한다. 이를 읽기 스키마라고 한다.  

읽기 스키마는 DB 내부 형식으로 데이터를 읽거나 파싱하거나 디스크에 직렬화할 필요가 없기 때문에 초기에 매우 빠른 속도로 데이터를 로드할 수 있다. 따라서 로드 조작을 위해서는 단순히 파일을 복사하거나 이동하기만 하면 된다.  

쓰기 스키마는 DB가 컬럼 단위의 데이터 색인과 압축을 제공하기 때문에 더 빠르게 쿼리를 수행할 수 있다. 하지만 상대적으로 DB에 데이터를 로드하는 시간은 더 오래 걸린다. 더욱이 쿼리가 정해지지 않아서 로드 시점에 스키마를 지정할 수 없고 색인도 적용할 수 없는 경우도 빈번하다. 이런 상황에서는 하이브가 빛을 발하게 된다.  

하이브는 테이블과 파티션 수준의 잠금을 지원한다. 특정 프로세스가 테이블을 읽는 도중에 다른 프로세스가 테이블을 삭제하는 것을 방지할 수 있따. 잠금은 주키퍼에 의해 투명하게 관리되므로 사용자가 직접 주키퍼를 조작하여 잠금을 적용하거나 해제할 수는 없다.  

<br/>

## 테이블

하이브 테이블은 '저장된 데이터'와 '테이블에서 데이터의 배치를 기술하는 관련 메타데이터'로 논리적으로 구성된다.  
데이터는 로컬 파일시스템이나 S3를 포함하여 어떠한 하둡 파일 시스템에도 둘 수 있지만 일반적으로 HDFS에 둔다.  
하이브는 HDFS가 아닌 관계형 데이터베이스에 메타데이터를 저장한다.  

### 관리 테이블과 외부 테이블

사용자가 데이터를 관리 테이블에 로드할 때 그 데이터는 하이브의 웨어하우스 디렉터리로 이동하게 된다.  

```sh
CREATE TABLE managed_table (dummy STRING);
LOAD DATA INPATH '/user/tom/data.txt' INTO table managed_table;
```

위의 명령은 data.txt 파일을 managed_table 테이블에 대한 하이브의 웨어하우스 디렉터리인 hdfs://user/hive/warehouse/managed_table로 이동시킨다.  

만약 DROP 구문으로 테이블을 제거하면 메타스토어와 함께 그 데이터도 삭제된다.  

만약 외부 테이블이라면 하이브가 데이터를 직접 관리할 필요가 없기 때문에 그 데이터를 웨어하우스 디렉터리로 이동시키지 않는다. 외부 데이터를 삭제할 때 하이브는 데이터는 절대 건드리지 않고 메타데이터만 삭제한다.  

<Br/>

### 파티션과 버킷

하이브는 테이블을 **파티션**으로 구조화할 수 있다. 파티션이란 테이블의 데이터를 날짜와 같은 **파티션 컬럼**의 값을 기반으로 큰 단위로 분할하는 방식이다. 파티션을 사용하면 데이터의 일부를 매우 빠르게 질의할 수 있다.  

테이블과 파티션은 효율적인 쿼리를 위해 데이터에 추가된 구조인 **버킷**으로 더욱 세분화될 수 있다. 예를 들어 사용자 ID를 기준으로 버킷을 생성하면 전체 사용자 중에서 무작위 데이터 샘플을 뽑아 사용자가 작성한 쿼리가 제대로 실행되는지 빠르게 평가할 수 있다.  

#### 파티션

만약 타임스탬프를 포함하고 있는 데이터에 대해서 파티션을 사용하면 동일한 날짜라면 동일한 파티션에 저장되기 때문에 특정 날짜나 기한으로 국한된 쿼리는 관련된 파티션에서만 파일을 읽기 때문에 매우 효율적이라는 장점을 가지고 있다.  

그리고 파티션 내에 서브파티션을 추가할 수도 있다.  

```shell
CREATE TABLE logs (ts BIGINT, line STRING)
PARTITIONED BY (dt STRING, country STRING);
```

파티션이 정의된 테이블로 데이터를 로드할 때는 파티션 값을 명시적으로 지정해야 한다.  

```shell
LOAD DATA LOCAL INPATH 'input/hive/partitions/file1'
INTO TABLE logs
PARTITION (dt='2001-01-01', country='GB')
```

<img width="262" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/acc9f8d2-0d80-4af3-92d9-db5bd80c1eab">

파일 시스템 수준에서 보면 파티션은 단순히 테이블 디렉터리에 내포된 서브 디렉터리다.  

```shell
hive> SHOW PARTITIONS logs;
dt=2001-01-01/country=GB
dt=2001-01-01/country=US
dt=2001-01-02/country=GB
dt=2001-01-02/country=US
```

SHOW PARTITIONS로 테이블에 포함된 파티션의 목록을 하이브에 요청할 수 있다.  

#### 버킷

테이블을 버킷으로 구조화하게되면 매우 효율적인 쿼리가 가능해진다. 버켓팅은 테이블에 대한 추가 구조를 부여하고, 하이브는 어떤 쿼리를 수행할 때 이 추가 구조를 이용할 수 있다. 특히 동일한 컬럼에 대한 버킷을 가진 두 테이블을 조인할 때 맵 조인을 구현하면 매우 효율적이다.  

두 번째로 효율적인 샘플링에 유리하다. 매우 큰 데이터셋을 대상으로 개발하거나 개선하는 과정에서 데이터셋의 일부만으로 쿼리를 수행할 수 있으면 매우 편리하다.  

```shell
CREATE TABLE bucketed_users (id INT, name STRING)
CLUSTERED BY (id) INTO 4 BUCKETS;
```

CLUSTERED BY 절로 버킷 수와 버킷 기준 컬럼을 지정했고, 하이브는 사용자 ID의 값을 해싱하고, 그 값을 버킷 수로 나눈 나머지를 버킷의 번호로 선택한다. 그러면 각 버킷은 사용자의 무작위 집합을 포함하는 효과가 있다.  

동일한 방식으로 버킷된 두 개의 테이블에 맵 조인을 수행하면 왼쪽 테이블의 버킷을 처리하는 매퍼는 상응하는 행이 오른쪽 테이블의 버킷에 있다는 것을 사전에 인지하고 있기 때문에 조인을 수행할 때 오른쪽 테이블에 저장된 전체 데이터의 작은 일부만 추출한다. 두 테이블의 버킷 수가 정확하게 같지 않아도 최적화가 가능하다.  

```shell
CREATE TABLE bucketed_users (id INT, name STRING)
CLUSTERED BY (id) SORTED BY (id ASC) INTO 4 BUCKETS;
```

버킷에 포함된 데이터는 하나 이상의 컬럼으로 정렬될 수 있다. 이렇게 하면 각 버킷을 조인할 때 효율적인 병합 정렬이 가능하므로 맵 조인의 속도를 더 향상시킬 수 있다.  

버킷이 적용되지 않은 테이블이 있을 때 ``hive.enforce.bucketing`` 속성을  true로 설정하여 테이블 정의에 선언된 개수만큼 버킷을 생성하도록 하이브에 알려주어야 한다. 그러고 나서 단순히 INSERT 명령을 실행하면 된다.  

물리적으로 각 버킷은 테이블이나 파티션 디렉터리 안에 있는 하나의 파일이다. 파일의 이름은 중요하지 않지만 사전순으로 배치될 때 버킷 n은 n번째 파일이라는 점을 기억하자. 사실 버킷은 맵리듀스 출력 파일 파티션에 상응한다. 다른 말로 하면 잡은 리듀스 태스크와 동일한 개수의 버킷(출력파일)을 생성한다.  

```shell
SELECT * FROM bucketed_users
TABLESAMPLE(BUCKET 1 OUT OF 4 ON id);
```

전체 테이블이 아니라 테이블의 일부 버킷만 사용하는 쿼리로 제한하는 TABLESAMPLE 절을 이용하여 해당 테이블을 샘플링하면 동일한 결과를 얻을 수 있다.  

``TABLESAMPLE(BUCKET 1 OUT OF 2 ON id)`` 라면 버킷의 절반을 반환한다.  

``TABLESAMPLE(BUCKET 1 OUT OF 4 ON rand())`` 는 버킷이 없는 테이블을 rand() 함수로 샘플링 하는 경우다. 이 경우에는 매우 작은 샘플만 필요하지만 전체 입력 데이터셋을 읽어야 한다.  

<br/>

### 저장 포맷

하이브는 두 개의 차원, 즉 **로우 포맷**과 **파일 포맷**으로 테이블 저장소를 관리한다. 로우 포맷은 행과 특정 행의 필드가 저장된 방식을 지시한다. 로우 포맷은 직렬자-역직렬자를 혼합한 하이브 전문 용어인  SerDe로 정의된다.  

---

