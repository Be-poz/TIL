# 파드와 클러스터 노드의 오토스케일링

## 수평적 파드 오토스케일링

수평적 파드 오토스케일링은 컨트롤러가 관리 파드의 레플리카 수를 자동으로 조정하는 것을 말한다. 이것은 Horizontal 컨트롤러에 의해 수행되며, HorizontalPodAutoScaler(HPA) 리소스를 작성해 활성화시키고 원하는 대로 설정한다. 컨트롤러는 주기적으로 파드 메트릭을 확인해, HorizontalPodAutoScaler 리소스에 설정돼 있는 대상 메트릭 값을 만족하는 레플리카 수를 계산한다. 그리고 대상 리소스 안에 있는 replicas 필드 값을 조절한다.  

<Br/>

### 오토스케일링 프로세스 이해

1. 확장 가능한 리소스 오브젝트에서 관리하는 모든 파드의 메트릭을 가져온다.
2. 메트릭을 지정한 목표 값과 같거나 가깝도록 하기 위해 필요한 파드 수를 계산한다.
3. 확장 가능한 리소스의 replicas 필드를 갱신한다.

#### 파드 메트릭 얻기

오토스케일러는 파드 메트릭을 수집하지 않고, 다른 소스에서 메트릭을 가져온다. 파드와 노드 메트릭은 모든 노드에서 실행되는 kubelet에서 실행되는 cAdvisor 에이전트에 의해 수집된다. 수집한 메트릭은 클러스터 전역 구성 요소인 힙스터에 의해 집계된다. 수평적 파드 오토스케일러 컨트롤러는 힙스터에 REST를 통해 질의해 모든 파드의 메트릭을 가져온다.  

<img width="723" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/6918edc3-59a3-48d2-9bdd-33dce1af4d97">

이 흐름은 오토스케일링이 동작하기 위해서는 힙스터가 동작해야 한다는 것을 의미한다.

이것은 쿠버네티스 버전 1.6 이전인 상황이고 1.8에서는 오토스케일러가 리소스 메트릭의 집계된 버전 API를 통해 얻을 수 있다. 

#### 필요한 파드 수 계산

오토스케일러의 스케일링 대상이 되는 리소스에 속해 있는 파드의 모든 메트릭을 가지고 있으면, 이 메트릭을 사용해 필요한 레플리카 수를 파악할 수 있다.  
모든 레플리카에서 메트릭의 평균 값을 이용해 지정한 목표 값과 가능한 가깝게 하는 숫자를 찾아야 한다. 이 계산의 입력은 파드 메트릭 세트이고, 출력은 하나의 정수이다.  

오토스케일러가 단일 메트릭만을 고려하도록 설정돼 있다면 필요한 레플리카 수를 계산하는 것은 간단한다. 모든 파드의 메트릭 값을 더한 뒤 HPA 리소스에 정의된 목표 값으로 나눈 값을 그 다음으로 큰 정수로 반올림해서 구한다.  

오토스케일링이 여러 파드 메트릭을 기반으로 하는 경우 계싼이 그렇게 복잡하지는 않다. 오토스케일러는 각 메트릭의 레플리카 수를 개별적으로 계산한 뒤 가장 높은 값을 취한다.  

<img width="723" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/2ab529e3-98df-4540-9295-767abb3b9c8c">

#### 스케일링된 리소스의 레플리카 수 갱신

오토스케일링 작업의 마지막 단계는 스케일링된 리소스 오브젝트의 레플리카 개수 필드를 원하는 값으로 갱신해, 레플리카셋 컨트롤러가 추가 파드를 시작하거나 초과한 파드를 삭제하도록 하는 것이다.  

오토스케일러 컨트롤러는 스케일 대상 리소스의 replicas 필드를 스케일 서브 리소스를 통해 변경한다. 이는 스케일 서브 리소스를 통해 노출되는 것을 제외하고, 오토스케일러가 리소스의 세부 사항을 알 필요 없이 수행할 수 있게 해준다.  

<img width="774" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/83cd5899-54f2-41ba-9cbb-9aeaf819a6c8">

API 서버가 스케일 서브 리소스를 노출하는 한, 오토스케일러는 모든 확장 가능한 리소스를 대상으로 동작할 수 있따. 현재 노출되는 리소스는 다음과 같다.

* 디플로이먼트
* 레플리카셋
* 레플리케이션 컨트롤러
* 스테이트풀셋

#### 전체 오토스케일링 과정 이해

<img width="819" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/f64ae103-c496-4d68-9ae4-ddeec89ea2ef">

메트릭 데이터가 전파돼 재조정 작업이 수해오디기까지는 시간이 걸린다. 즉각적으로 이루어지지 않는다.  

<br/>

### CPU 사용률 기반 스케일링

오토스케일러에 한해서는 파드의 CPU 사용률을 결정할 때 파드가 보장받은 CPU 사용량만이 중요하다. 오토스케일러는 파드의 실제 CPU 사용량과 CPU 요청을 비교하는데, 이는 오토스케일링이 필요한 파드는 오토스케일러가 CPU 사용률을 결정하기 위해서 오토스케일링이 필요한 파드는 직접 또는 간접적으로 LimitRange 오브젝트를 통해 CPU 요청을 설정해야 한다는 것을 의미한다.  

#### CPU 사용량을 기반으로 HorizontalPodAutoscaler 생성

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kubia
spec:
  replicas: 3
  selector:
    matchLabels:
      app: kubia
  template:
    metadata:
      name: kubia
      labels:
        app: kubia
    spec:
      containers:
      - image: luksa/kubia:v1
        name: nodejs
        resources:			# 파드당 100밀리코어의 CPU 요청
          requests:
            cpu: 100m	
```

HPA 리소스를 매니페스트를 준비하여 생성하는 방법도 있지만, ``k autoscale deployment kubia --cpu-percent=30 --min=1 --max=5`` 와 같이 명령어로도 수행 가능하다.  
위 명령은 파드의 목표 CPU 사용률으 30%로 지정하고 최소 및 최대 레플리카 수를 지정한다. 오토스케일러는 CPU 사용률을 30%대로 유지하기 위해 레플리카 수를 조정하지만 1개 미만으로 줄이거나 5개를 초과하는 레플리카를 만들지는 않는다.  

```yaml
apiVersion: autoscaling/v2									# HPA 리소스는 오토스케일링 API 그룹에 속해있다
kind: HorizontalPodAutoscaler
metadata:
  creationTimestamp: "2023-07-02T05:41:42Z"
  name: kubia																# 각 HPA는 이름을 갖고 deployment와 일치하지 않아도 된다.
  namespace: bepoz
  resourceVersion: ...
  uid: ...
spec:
  maxReplicas: 5
  metrics:																	# 오토스케일러가 파드 수를 조정해 각 파드가 요청 CPU의 30%를 사용하도록 한다.
  - resource:
      name: cpu
      target:
        averageUtilization: 30
        type: Utilization
    type: Resource
  minReplicas: 1
  scaleTargetRef:														# 오토스케일러가 제어할 목표 리소스
    apiVersion: apps/v1
    kind: Deployment
    name: kubia
status:																			# 오토스케일러의 현재 상태
  conditions:
...
  currentMetrics:
  - resource:
      current:
        averageUtilization: 0
        averageValue: "0"
      name: cpu
    type: Resource
  currentReplicas: 3
  desiredReplicas: 3
```

``k get deploy``를 해보면 replicas가 1개로 준 것을 확인할 수가 있을 것이다.  

``k describe hpa`` 를 해보면 아래와 같이 나온다.  

```shell
Name:                                                  kubia
Namespace:                                             bepoz
Labels:                                                <none>
Annotations:                                           <none>
CreationTimestamp:                                     Sun, 02 Jul 2023 14:41:42 +0900
Reference:                                             Deployment/kubia
Metrics:                                               ( current / target )
  resource cpu on pods  (as a percentage of request):  0% (0) / 30%
Min replicas:                                          1
Max replicas:                                          5
Deployment pods:                                       1 current / 1 desired
Conditions:
  Type            Status  Reason            Message
  ----            ------  ------            -------
  AbleToScale     True    ReadyForNewScale  recommended size matches current size
  ScalingActive   True    ValidMetricFound  the HPA was able to successfully calculate a replica count from cpu resource utilization (percentage of request)
  ScalingLimited  True    TooFewReplicas    the desired replica count is less than the minimum replica count
Events:
  Type    Reason             Age   From                       Message
  ----    ------             ----  ----                       -------
  Normal  SuccessfulRescale  36s   horizontal-pod-autoscaler  New size: 1; reason: All metrics below target
```

#### 스케일 업 일으키기

이제 CPU 사용량을 증가시켜 오토스케일러가 이를 감지해 추가 파드를 시작하게끔 해보자.  

``k expose deploy kubia --port=80 --target-port=80`` 로 간단하게 서비스를 생성해두고,  

``k run -it --rm --restart=Never loadgenerator --image=busybox -- sh -c "while true; do wget -O - -q http://kubia.<namespace>; done"`` 를 이용하여 계속 호출하게하고 describe 해보면 replicas가 늘어난 것을 확인할 수가 있다.  

#### 기존 HPA 오브젝트에서 목표 메트릭 값 변경

``k edit`` 을 이용해 메트릭 값 변경을 할 수 있다.  

```yaml
spec:
  maxReplicas: 5
  metrics:
  - resource:
      name: cpu
      target:
        averageUtilization: 30
        type: Utilization
    type: Resource
```

위의 ``averageUtilization`` 항목을 변경하여 CPU 사용률 목표를 변경할 수 있다. 대부분의 다른 리소스와 마찬가지로 리소스를 수정한 후에 변경 사항은 오토스케일러 컨트롤러에 의해 감지돼 동작한다.  

<Br/>

### 기타 그리고 사용자 정의 메트릭 기반 스케일링

```yaml
spec:
	maxReplicas: 5
  metrics:
  - type: Resource			# 메트릭 유형을 지정
  	resource:
      name: cpu					# 사용률을 모니터링할 리소스
      target:
        averageUtilization: 30	# 목표 사용률
```

metric 필드에는 사용할 하나 이상의 메트릭을 정의할 수 있다. 

* 리소스
* 파드
* 오브젝트

이렇게 3 가지 유형의 메트릭이 있다. 위의 예시에서는 타입을 지정해줬는데 1.6 버전 이후로는 생략할 수 있다고 한다. 그런데 이게 파드와 오브젝트의 경우에도 생략가능한지는 자세히 모르겠다.  

#### 파드 메트릭의 이해

POds 유형은 파드와 관련된 다른 메트릭을 직접 참조하는 데 사용된다. 이런 메트릭의 예로는 이미 언급했던 초당 질의 수(QPS) 또는 메세지 브로커의 큐 메세지 수 등이 있다.  

```yaml
spec:
	maxReplicas: 5
  metrics:
  - type: Pods			# 메트릭 유형을 지정
  	resource:
      metricName: qps					# 사용률을 모니터링할 리소스
      targetAverageValue: 100	# 모든 대상 파드의 목표 평균 값
```

모든 파드에서 평균 QPS가 HPA 리소스에 정의한 목표 값이 100을 유지하도록 설정한다.  

#### 오브젝트 메트릭 유형 이해

```yaml
spec:
  metrics:
  - type: Object
    resource:
      metricName: latencyMillis
      target:
        apiVersion: extensions/v1beta1
        kind: Ingress
        name: frontend
      targetValue: 20
```

위 예제에서 HPA는 frontend 인그레스 오브젝트의 latencyMillis 메트릭을 사용하도록 설정돼 있다. 수평적 파드 오토스케일러는 인그레스의 메트릭을 모니터링하고 목표 값보다 높이 올라갈 경우 오토스케일러가 kubia 디플로이먼트 리소스를 확장한다.  

<Br/>

### 오토스케일링에 적합한 메트릭 결정

오토스케일러 애플리케이션 정의 메트릭을 오토스케일러의 기반 항목으로 하기 전에, 파드 수가 증가하고 감소할 때 메트릭 값이 어떻게 변화하는지 고려해야 한다.  

<Br/>

### 레플리카를 0으로 감소

수평적 파드 오토스케일러는 minReplicas 필드를 0으로 설정할 수 없기 때문에, 파드가 아무것도 하지 않더라도 오토스케일러는 파드 수를 0으로 감소시키지 않는다. 파드 수를 0으로 축소할 수 있게 만들면 하드웨어 사용률이 크게 높아질 수 있다. 이를 유휴(idling), 유휴 해제(un-idling)라고 한다. 아직 쿠버네티스에서 기능 제공을 하고 있지는 않다.  

<Br/>

## 수평적 클러스터 노드 확장

수평적 파드 오토스케일러는 필요할 때 추가 파드 인스턴스를 생성한다. 그러나 모든 노드가 한계에 도달해 더 이상 파드를 추가할 수 없을 때는 어떻게 될까?  

이 경우에는 기존 파드 중 몇 개를 삭제하거나 파드가 사용하는 자원을 줄이거나 새로운 노드를 추가해야 한다.  

<br/>

### 클러스터 오토스케일러 소개

클러스터 오토스케일러는 노드에 리소스가 부족해서 스케줄링할 수 없는 파드를 발견하면 추가 노드를 자동으로 공급한다. 또한 오랜 시간 동안 사용률이 낮으면 노드를 줄인다.  

#### 클라우드 인프라스트럭처에 추가 노드 요청

<img width="725" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/d158405f-77eb-432d-92d8-a60da904dc4d">

새 노드가 시작되면, 해당 노드의 kubelet이 API 서버에 접속해 노드 리소스를 만들어 노드를 등록한다.  

#### 노드 종료

클러스터 오토스케일러는 모든 노드에 요청된 CPU와 메모리를 모니터링해 이를 수행한다. 특정 노드에서 실행 중인 모든 파드의 CPU와 메모리 요청이 50% 미만이면 해당 노드는 필요하지 않은 것으로 간주한다. 오토스케일러는 해당 노드에서만 실행 중인 시스템 파드가 있는지 검사한다(데몬셋 등으로 모든 노드에 배포되는 시스템 파드는 제외한다). 만약 시스템 파드가 노드에서 실행 중이라면 해당 노드는 종료될 수 없다. 관리되지 않는 파드나 로컬 저장소를 가진 파드가 실행되는 경우에도 마찬가지다. 파드가 제공하는 서비스가 중단될 수 있기 때문이다. 다르게 말하면 클러스터 오토스케일러가 노드에서 실행 중인 파드가 다른 노드로 다시 스케줄링될 수 있다는 것을 알고 있는 경우에만 해당 노드가 클라우드 제공자에게 반환될 수 있다.  

종료할 노드로 선택되면, 해당 노드는 먼저 스케줄링할 수 없다는 표시를 하고 노드에서 실행 중인 모든 파드를 제거한다. 제거하는 모든 파드는 레플리카셋이나 다른 컨트롤러에 속해 있기 때문에, 교체할 파드가 생성되고 남아 있는 나머지 노드에 스케줄링된다.  

<br/>

	### 클러스터 스케일 다운 동안에 서비스 중단 제한

노드가 예기치 않게 실패할 경우 파드가 사용 불가 상태가 되는 것을 막을 수 있는 방법이 없다. 하지만 노드 종료가 클러스터 오토스케일러나 시스템 관리자로 인해 이뤄지는 상황이라면, 추가 기능을 통해 해당 노드에서 실행되는 파드가 제공하는 서비스를 중단되지 않도록 할 수 있다.  

Pod DisruptionBudget 리소스를 만들어 이를 수행할 수 있다. 파드 레이블 셀렉터와 항상 사용 가능해야 하는 파드의 최소 개수 혹은 파드의 최대 개수를 정의할 수 있다.  

``k create pdb kubia-pdb --selector=app=kubia --min-available=3`` 명령어로 생성하고 yaml을 확인해보겠다.  

```yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  creationTimestamp: "2023-07-02T06:56:10Z"
  generation: 1
  name: kubia-pdb
  namespace: bepoz
  resourceVersion: ...
  uid: ...
spec:
  minAvailable: 3		# 얼마나 많은 파드를 항상 사용 가능하게 할 것인가
  selector:					# 이 budget을 적용할 파드를 결정하는 레이블 셀렉터
    matchLabels:
      app: kubia
status:
  conditions:
  - lastTransitionTime: "2023-07-02T06:56:10Z"
    message: ""
    observedGeneration: 1
    reason: InsufficientPods
    status: "False"
    type: DisruptionAllowed
  currentHealthy: 1
  desiredHealthy: 3
  disruptionsAllowed: 0
  expectedPods: 1
  observedGeneration: 1
```

``minAvailable`` 필드에 절댓값이 아닌 백분율을 사용할 수도 있다. 예를 들어 app=kubia 레이블을 가진 모든 파드 중 60%의 파드가 항상 실행되는 상태를 지정할 수 있다. 리소스가 존재하는 동안 클러스터 오토스케일러와 와  kubectl drain 명령 모두 이를 준수해 app-kubia 레이블을 가진 파드가 정의해둔 수 이하로 줄어들지 안ㅇㅎ는다.  

예를 들어 4개의 파드가 있고 ``minAvailable``을 3개로 설정한 경우 파드 제거 프로세스는 파드를 하나씩 제거하는데, 이때 다른 파드를 제거하기 전에 레플리카셋 컨트롤러가 제거된 파드를 새 파드로 교체하기를 기다린다.  

---

