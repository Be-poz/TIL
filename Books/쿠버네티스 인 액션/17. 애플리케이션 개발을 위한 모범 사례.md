# 애플리케이션 개발을 위한 모범 사례

## 모든 것을 하나로 모아 보기

<img width="838" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/900d859f-127c-4595-a37c-83c38fc530b6">

일반적인 애플리케이션 매니페스트에는 하나 이상의 디플로이먼트나 스테이트풀셋 오브젝트가 포함된다. 여기에는 하나 이상의 컨테이너가 포함된 파드 템플릿, 각 컨테이너에 대한 라이브니스 프로브와(있는 경우) 컨테이너가 제공하는 서비스에 대한 레디니스 프로브가 포함된다. 다른 사람에게 서비스를 제공하는 파드는 하나 이상의 서비스로 노출된다. 클러스터 외부로 통신할 수 있어야 하는 경우 서비스는 로드밸런서나 노드포트 유형 서비스로 구성되거나 인그레스 리소스로 노출된다.  

파드 템플릿은 일반적으로 프라이빗 이미지 레지스트리에서 컨테이너 이미지를 가져오는 데 사용되는 시크릿과 파드 내에 실행되는 프로세스에서 직접 사용되는 시크릿을 참조한다. 시크릿은 일반적으로 애플리케이션 개발자가 아니라 운영팀이 구성하기 때문에 애플리케이션 매니페스트의 일부는 아니다. 시크릿은 일반적으로 개별 파드에 할당된 서비스어카운트에 할당한다.  

애플리케이션에는 환경변수를 초기화하거나 파드에 컨피그맵 볼륨으로 마운트되는 하나 이상의 컨피그맵이 포함돼 있다. 특정 파드는 emptyDir 또는 girRepo 볼륨과 같은 추가 볼륨을 사용하는 반면, 퍼시스턴트 스토리지가 있어야 하는 파드는 퍼시스턴트 볼륨 클레임 볼륨을 사용한다. 퍼시스턴트 볼륨 클레임은 애플리케이션 매니페스트에 속하며, 이에 의해 참조된 스토리지클래스는 시스템 관리자가 미리 생성한다.  

경우에 따라 애플리케이션에서 잡이나 크론잡을 사용해야 한다. 데몬셋은 일반적으로 애플리케이션 디플로이먼트의 일부는 아니지만 일반적으로 시스템 운영자가 노드 전체 또는 일부에 시스템 서비스를 실행하려고 생성한다. 수평 파드 오토 스케일러는 개발자가 매니페스트에 포함시키거나 나중에 운영팀이 시스템에 추가한다. 또한 크러스터 관리자는 제한 범위와 리소스쿼터 오브젝트를 생성해 개별 파드와 모든 파드의 리소스 사용량을 제어할 수 있다.  

애플리케이션이 배포되면 다양한 쿠버네티스 컨트롤러에 의해 오브젝트가 추가적으로 자동 생성된다. 여기에는 엔드포인트 컨트롤러로 생성된 서비스 엔드포인트 오브젝트, 디플로이먼트 컨트롤러로 생성된 레플리카셋과 레플리카셋, 잡, 크론잡, 스테이트풀셋, 데몬셋 컨트롤러로 생성된 실제 파드가 포함된다.  

리소스는 종종 체계적으로 유지되기 위해 하나 이상의 레이블을 지정한다. 이는 파드에만 적용되는 것이 아니라 다른 모든 리소스에도 적용된다. 레이블 외에도 대부분의 리소스에는 각 리소스를 설명하거나 해당 담당자 또는 팀의 연락처 정보를 나열하거나 관리와 기타 도구에 관한 추가 메타데이터를 제공하는 어노테이션이 포함돼 있다.  

이 중심에는 파드가 있다. 가장 중요한 쿠버네티스 리소스다. 결국 각 애플리케이션은 파드 내부에서 실행된다. 환경을 최대한 활용하는 애플리케이션을 개발하는 방법을 알려면, 애플리케이션 관점에서 파드를 자세히 살펴봐야 한다.  

<br/>

## 파드 라이프사이클 이해

### 애플리케이션을 종료하고 파드 재배치 예상하기

쿠버네티스 환경이 아닌 경우 가상머신에서 실행되는 애플리케이션은 한 시스템에서 다른 시스템으로 이동하는 경우가 드물다.  
쿠버네티스를 사용하면 애플리케이션이 훨씬 더 자주 자동으로 재배치된다.  

#### 로컬 IP와 호스트 이름 변경 예상하기

파드가 종료되고 다른 곳에서 실행되면 새로운 IP 주소뿐만 아니라 새로운 이름과 호스트 이름을 갖는다. 대부분의 스테이트리스 애플리케이션은 일반적으로 문제없이 처리할 수 있지만 스테이트풀 애플리케이션은 그렇지 않다. 스테이트풀 애플리케이션을 스테이트풀셋으로 실행할 수 있다는 사실을 알고 있으므로 스케줄링을 조정한 후 새 노드에서 애플리케이션을 시작할 때도 여전히 이전과 동일한 호스트 이름과 퍼시스턴트 상태를 볼 수 있다. 그럼에도 파드의 IP는 변경될 것이다. 이를 위해서 애플리케이션이 미리 준비돼 있어야 한다. 따라서 애플리케이션 개발자는 클러스터된 애플리케이션의 구성원을 IP 주소 기반으로 하면 안 되며 호스트 이름을 기반으로 할 때에도 항상 스테이트풀셋을 사용해야 한다.  

#### 디스크에 기록된 데이터가 사라지는 경우 예상하기

애플리케이션이 디스크에 데이터를 쓰는 경우 애플리케이션이 쓰는 위치에 퍼시스턴트 스토리지를 마운트하지 않으면 애플리케이션이 새 파드로 시작된 후에 해당 데이터를 사용하지 못할 수 있다는 것이다. 파드를 다시 스케줄링하면 이러한 상황이 발생하는 게 명확하지만 스케줄링과 관련되지 않는 경우에도 디스크에 기록된 파일은 사라질 수 있다. 파드의 라이프사이클 동안에도 파드에서 실행되는 애플리케이션이 디스크에 쓴 파일은 사라질 수 있다.  

예로들면, 애플리케이션이 재시작할 때 더 빨리 시작되도록 개발자는 디스크에 초기 시작 결과를 애플리케이션 캐시로 만든다. 쿠버네티스의 패를리케이션은 기본적으로 컨테이너에서 실행되므로 이러한 파일은 컨테이너의 파일시스템에 만든다. 컨테이너가 다시 시작되면 새 컨테이너는 완전히 새로운 쓰기 가능한 레이어로 시작하기 때문에 이전 파일은 모두 손실된다.  

프로세스 크래시나 라이브니스 프로브가 실패를 반환했거나 노드의 메모리 부족이 시작돼 프로세스가 OOMKiller에 의해 종료된 경우와 같이 여러 가지 이유로 컨테이너가 다시 시작될 수 있다. 이 경우 파드는 여전히 동일하지만 컨테이너 자체는 완전히 새로운 것이다. Kubelet은 동일한 컨테이너를 다시 실행하지 않는다. 항상 새 컨테이너를 만든다.  

<img width="809" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/fe426f8b-5650-4e7b-b56e-5c1bac1d755e">

#### 컨테이너를 다시 사용하더라도 데이터를 보존하기 위해 볼륨 사용하기

<img width="738" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/de2bc23f-0db0-4cf9-9ec0-53459a1c5801">

컨테이너를 재시작할 때 파일을 보존하려고 볼륨을 사용하는 것은 좋은 생각이지만 항상 그런 것은 아니다. 데이터가 손상돼 새로 생성된 프로세스가 다시 크래시되면 어떻게 할까? 이로 인해 연속  크래시 루프가 발생한다(파드에 ``CrashLoopBackOff`` 상태가 표시됨). 볼륨을 사용하지 않은 경우 새 컨테이너가 처음부터 시작돼 크래시하지 않을 가능성이 높다. 컨테이너를 재시작할 때 파일을 보존하려고 볼륨을 사용하는 것은 양날의 검이다.  

<br/>

### 종료된 파드 또는 부분적으로 종료된 파드를 다시 스케줄링하기

파드의 컨테이너가 계속 크래시되면 Kubelet은 계속 파드를 재시작한다. 재시작 간격은 5분이 될 때까지 간격이 증가한다.  
멀티 컨테이너 파드인 경우 엄밀하게 말해 특정 컨테이너가 정상적으로 작동할 수 있으므로 파드는 일부만 종료된 것으로 볼 수 있다. 그러나 파드에 컨테이너가 하나만 포함돼 있으면 더 이상 프로세스가 실행되지 않기 때문에 파드가 실제로 종료된 것이고 완전히 쓸모가 없어진다.  

의도하는 레플리카수가 3인 레플리카셋을 만든 다음 해당 파드 중 하나에서 컨테이너가 크래시하기 시작해도 쿠버네티스는 해당 파드를 삭제하고 교체하지 않는다. 결론적으로 의도하는 세 개의 레플리카가 아닌 제대로 실행되는 두 개의 레플리카가 있는 레플리카셋을 가진다.  

<img width="659" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/1fd55377-3f13-4f46-af78-83e5906129e4">

파드가 삭제되고 다른 노드에서 성공적으로 실행될 수 있는 다른 파드 인스턴스로 교체되기 원할 것이다. 결국 다른 노드에서는 나타나지 않은 노드 관련 문제로 인해 컨테이너가 중단될 수 있다. 슬프게도, 레플리카셋 컨트롤러는 파드가 죽은 상태가 됐는지 상관하지 않는다. 관심 있는 것은 파드 수가 의도하는 레플리카 수와 일치하느냐하는 것이다.  

<br/>

### 원하는 순서로 파드 시작

파드에서 실행되는 애플리케이션과 수동으로 관리되는 애플리케이션의 또 다른 차이점은 애플리케이션을 배포하는 담당자가 애플리케이션 간의 의존성을 알고 있다는 것이다. 이것은 애플리케이션을 순서대로 시작할 수 있게 해준다.  

#### 파드 시작 방법

쿠버네티스로 파드 애플리케이션 여러 개를 실행할 때 쿠버네티스가 특정 파드를 먼저 실행하고 첫 번째 파드가 서비스할 준비가 됐을 때 나머지 파드를 실행하도록 지시할 방법이 기본적으로 없다. 쿠버네티스 API 서버는 YAML/JSON의 오브젝트를 나열된 순서대로 처리하지만 이는 etcd에 순서대로 기록됨을 의미한다. 파드가 그 순서대로 시작된다는 보장은 없다. 그러나 전체 조건이 충족될 때까지 파드의 주 컨테이니ㅓ가 시작되지 않도록 할 수 있다. 이것은 파드에 초기화 컨테이너를 포함시켜 수행된다.  

#### 초기화 컨테이너 소개

일반 컨테이너 외에도 파드는 초기화 컨테이너를 포함할 수 있다. 이름에서 알 수 있듯이 파드를 초기화하는 데 사용한다. 이는 주 파드의 볼륨에 데이터를 쓴 다음 주 컨테이너에 마운트하는 것을 의미한다.  

파드는 여러 개의 초기화 컨테이너를 가질 수 있다. 순차적으로 실행되며 마지막 컨테이너가 완료된 후에 파드의 주 컨테이너가 시작된다. 즉, 초기화 컨테이너를 사용해 파드의 주 컨테이너 시작을 지연시킬 수 있다. 초기화 컨테이너로 파드의 주 컨테이너에 필요한 서비스가 준비될 때까지 기다릴 수 있다. 주 컨테이너가 시작되면, 초기화 컨테이너는 종료되고 주 컨테이너가 시작될 수 있게 한다. 이렇게 하면 주 컨테이너가 준비되기 전까지 서비스를 사용하지 않게 된다.  

주 컨테이너가 시작되기 전에 fortune 서비스를 시작하고나서 실행해야 하는 fortune 클라이언트 파드가 있다고 가정해보자. 서비스가 요청에 응답하는지 여부를 확인하는 초기화 컨테이너를 추가할 수 있다. 이때까지 초기화 컨테이너는 계속 재시도한다. 응답을 받으면 초기화 컨테이너가 종료되고 주 컨테이너가 시작된다.  

#### 파드에 초기화 컨테이너 추가

초기화 컨테이너는 주 컨테이너와 같이 파드 스펙에 정의될 수 있지만 ``spec.initContainers`` 필드에 정의할 수도 있다.  

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: fortune-client
spec:
  initContainers:
  - name: init
    image: busybox
    command:
    - sh
    - -c
    - 'while true; do echo "Waiting for fortune service to come up..."; wget http://fortune -q -T 1 -O /dev/null >/dev/null 2>/dev/null && break; sleep 1; done; echo "Service is up! Starting main container."'
    # 초기화 컨테이너는 fortune 서비스가 가동될 때까지 루프를 실행한다
  containers:
  - image: busybox
    name: main
    command:
    - sh
    - -c
    - 'echo "Main container started. Reading fortune very 10 seconds."; while true; do echo "-------------"; wget -q -O - http://fortune; sleep 10; done'
```

![image](https://github.com/Be-poz/TIL/assets/45073750/8dbdbba0-86a6-436a-be30-6cbb255d37a6)

위 파드를 생성하고 확인해보면 STATUS가 조금 특이한 것을 알 수 있다. 초기화 컨테이너 중 0개가 완료됐음을 나타내고 있다.  

#### 파드 간 의존성 처리를 위한 모범 사례

애플리케이션이 시작되기 전 준비 상태가 되기 위해 의존해야 할 서비스를 필요로 하지 않도록 애플리케이션을 만드는 것이 좋은 방법이다. 결국 애플리케이션이 실행 상태가 되더라도 서비스는 나중에 오프라인이 될 수 있다. 애플리케이션은 이러한 의존성이 준비되지 않았을 가능성을 내부적으로 처리해야 한다. 의존성이 누락돼 애플리케이션이 작업을 수행할 수 없는 경우 쿠버네티스가 레디니스 프로브로 이를 인식하고 준비가 되지 않았다는 신호를 보내야 한다. 애플리케이션을 서비스 엔드포인트에 추가되는 것을 방지할 뿐만 아니라, 롤링 업데이트를 수행할 때 디플로이먼트 컨트롤러에서 애플리케이션의 레디니스 상태를 사용해 잘못된 버전의 롤아웃을 방지하기 때문에 이 방법을 사용한다.  

<Br/>

### 라이프사이클 훅 추가

초기화 컨테이너를 사용해 파드 시작 시 사용하는 방법을 설명했지만, 파드는 라이프사이클 훅 두 가지를 정의할 수 있다.  

* 시작 후(post-start) 훅
* 종료 전(pre-stop) 훅

이런 라이프사이클 훅은 전체 파드에 적용되는 초기화 컨테이너와 달리 컨테이너 별로 지정된다.  
라이프사이클, 라이브니스 프로브, 레디니스 프로브와 유사하게 다음을 수행할 수 있다.  

* 컨테이너 내부에서 명령 실행
* URL로 HTTP GET 요청 수행

#### 컨테이너 시작 후 라이프사이클 훅 사용

시작 후 훅은 컨테이너의 주 프로세스가 시작된 직후에 실행된다. 애플리케이션이 시작될 떄 추가 작업을 수행하는 데 사용된다. 물론 컨테이너에서 실행 중인 애플리케이션 개발자라면 항상 애플리케이션 코드 내에서 해당 작업을 수행할 수 있지만 대부분 소스 코드를 수정하고 싶어 하지 않는다. 시작 후 훅을 사용하면 애플리케이션을 건드리지 않고도 추가 명령을 실행할 수 있다. 애플리케이션이 시작되고 있는 외부 리스너에게 시그널을 보내거나 애플리케이션을 초기화하는 작업을 시작할 수 있다.  

훅이 완료될 때까지 컨테이너는 ContainerCreating인 채로 Waiting 상태가 유지된다. 이 때문에 파드 상태는 Running 중이 아니라 Pending 상태다. 훅이 실행되지 않거나 0이 아닌 종료 코드를 반환하면 주 컨테이너가 종료된다.  

<br/>

### 파드 셧다운 이해하기

파드의 종료는 API 서버로 파드 오브젝트를 삭제하면 시작된다. HTTP DELETE 요청을 수신하면 API 서버는 아직 오브젝트를 삭제하지 않고 그 안에 deleteTimeStamp 필드만 설정한다. 그리고 deletedTimeStamp 필드가 설정된 파드가 종료된다.  

Kubelet은 파드를 종료해야 함을 확인하면 각 파드의 컨테이너를 종료하기 시작한다. 각 컨테이너에 정상적으로 종료하는 데 시간이 걸리지만 시간은 제한돼 있다. 이 시간을 종료 유예 기간이라고 하며 파드별로 구성할 수 있다. 종료 프로세스가 시작되자마자 타이머가 시작된다.  

1. 종료 전 훅(구성된 경우)을 실행하고 완료될 때까지 기다린다.
2. SIGTERM 신호를 컨테이너의 주 프로세스로 보낸다.
3. 컨테이너가 완전히 종료될 때까지 또는 종료 유예 기간이 끝날 때까지 기다린다.
4. 아직 정상적으로 종료되지 않은 경우 SIGKILL로 프로세스를 강제 종료한다.  

<img width="756" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/e58b0a68-e53e-47e7-9e40-60facd911141">

#### 종료 유예 기간 지정

종료 유예 기간은 파드 스펙에서 ``terminateGracePeriodSeconds`` 필드로 설정할 수 있다.  
기본값은 30이고 파드의 컨테이너는 강제 종료되기 전에 정상 종료할 수 있도록 30초가 주어진다.  

``k delete po mypod --grace-period=5`` 이렇게 파드를 삭제할 때 파드 스펙에 지정된 종료 유예 기간을 재정의할 수 있다.  

그러면 파드가 깨끗하게 종료될 때까지 kubelet이 5초 동안 기다린다. 모든 파드의 컨테이너가 중지되면 kubelet은 API 서버에 알리고 파드 리소스가 삭제된다. 유예 기간을 0으로 설정하고 다음과 같이 --force 옵션을 추가해 확인을 기다리지 않고 API 서버가 리소스를 즉시 삭제하도록 할 수 있다.  

``k delete po mypod --grace-period=0 --force``  

이 옵션을 사용할 때는 특히 스테이트풀셋 파드에 주의한다. 스테이트풀셋 컨트롤러는 동일한 파드의 두 인스턴스를 동시에 실행하지 않도록 유의한다. 파드를 강제 삭제하면 삭제된 파드의 컨테이너가 종료될 때까지 기다리지 않고 컨트롤러가 교체 파드를 생성하게 된다. 즉, 동일한 파드의 두 인스턴스가 동시에 실행돼 스테이트풀 클러스터가 오작동할 수 있다. 파드가 더 이상 실행되고 있지 않거나 클러스터의 다른 멤버와 대화할 수 없는 경우 스테이트풀 파드를 강제로 삭제한다.  

#### 애플리케이션에서 적절한 셧다운 핸들러 구현

애플리케이션은 SIGTERM 신호에 대응해 셧다운 절차를 시작하고 완료되면 종료해야 한다. SIGTERM 신호를 처리하는 대신, 종료 전 훅으로 애플리케이션을 종료하도록 알릴 수 있다. 두 경우 모두 애플리케이션이 성공적으로 완료하기 위한 일정 시간밖에 없다.  

애플리케이션이 분산 데이터 저장소라고 가정해보자. 스케일을 축소하면 파드 인스턴스가 제거되므로 종료된다. 종료 단계에서 파드는 모든 데이터를 나머지 파드로 마이그레이션해 데이터가 손실되지 않도록 해야 한다. 파드는 종료 신호를 수신하면 데이터 마이그레이션을 시작해야 할까? 아니다.  

* 컨테이너가 종료해도 파드 전체가 종료되는 것은 아니다
* 프로세스가 종료되기 전에 종료 절차가 끝난 것이라는 보장이 없다

두 번째 시나리오는 애플리케이션의 정상적인 종료가 수행되기 전에 종료 유예 기간이 만료될 때뿐만 아니라 컨테이너의 셧다운 단계 중간에 파드를 실행하는 노드가 실패하는 경우에도 발생한다. 그 후, 노드가 다시 시작하는 경우에도 kubelet은 셧다운 절차를 다시 시작하지 않는다. 파드가 전체 셧다운 단계 전체를 완료할 수 있다는 보장은 전혀 없다.  

#### 전용 셧다운 절차 파드를 사용해 중요한 셧다운 절차 대체

반드시 실행해야 하는 중요한 셧다운 절차가 완료될 때까지 셧다운 절차가 실행되도록 보장하는 방법이 있을까?  

한 가지 해결책은 애플리케이션이(종료 신호가 수신될 때) 새 파드를 실행하는 새로운 잡 리소스를 만드는 것이며, 그 역할은 삭제된 파드의 데이터를 나머지 파드로 옮기는 것이다. 그러나 주의해야 할 것은 애플리케이션이 잡 오브젝트를 매번 만들 수 있다는 보장이 없다는 것이다. 애플리케이션을 실행할 때 노드가 실패하면 어떻게 될까? 이 문제를 처리하는 적절한 방법은 분산된 데이터의 존재를 확인하는 전용 파드를 항상 실행하는 것이다. 이 파드가 분산된 데이터를 찾아 나머지 파드로 마이그레이션할 수 있다. 항상 실행되는 파드가 아니라 크론잡 리소스를 사용해 정기적으로 파드를 수행할 수 있다.  

<img width="640" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/e5ced3c9-5e18-4bd9-a764-927abc9eaad5">

<br/>

## 모든 클라이언트 요청의 적절한 처리 보장

### 파드가 시작될 때 클라이언트 연결 끊기 방지

파드가 시작되면 레이블 셀렉터가 파드의 레이블과 일치하는 모든 서비스의 엔드포인트에 추가된다. 파드는 쿠버네티스에 준비가 됐다는 신호를 보내야 한다. 그렇지 않으면 서비스 엔드포인트가 추가되지 않으므로 클라이언트로부터 요청을 받지 못한다.  

파드 스펙에 레디니스 프로브를 지정하지 않으면 파드는 항상 준비된 것으로 간주된다. 첫 번째 kube-proxy가 노드에서 iptables 규칙을 업데이트하고 첫 클라이언트 파드가 서비스에 연결을 시도하자마자 거의 즉시 요청을 수신하기 시작한다. 그때까지 애플리케이션이 연결을 수락할 준비가 되지 않으면 클라이언트에게 'connection refused'와 같은 오류가 나타난다.  

애플리케이션이 들어오는 요청을 올바르게 처리할 준비가 됐을 때만 레디니스 프로브가 성공을 반환하도록 해야 한다. 첫 번째 단계는 HTTP GET 레디니스 프로브를 추가하고 애플리케이션의 기본 URL을 가리키는 것이다. 대부분 정상 동작하며 애플리케이션에서 특별한 레디니스 엔드포인트를 구현하지 않아도 된다.  

<Br/>

### 파드 셧다운 동안 연결 끊어짐 방지

#### 파드 삭제 시 발생하는 이벤트의 순서 이해

API 서버가 파드 삭제 요청을 받으면 먼저 etcd의 상태를 수정한 다음 감시자에게 삭제를 알린다. 이러한 감시자 중에는 kubelet과 엔드포인트 컨트롤러가 있다.  

<img width="813" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/0caf3feb-7bb0-4edd-a9df-b7b9a91f2c08">

A 이벤트 순서에서 kubelet이 파드를 종료해야 한다는 알림을 받으면 앞에서 설명한대로 셧다운 순서를 시작한다. 애플리케이션이 클라이언트 요청을 즉시 받지 않음으로써 SIGTERM에 응답하는 경우 애플리케이션에 연결하려는 모든 클라이언트는 connection refused 오류를 수신한다.  
API 서버에서 kubelet까지 바로 파드가 삭제되는 시점까지 이 작업이 수행되는 데 걸리는 시간은 비교적 짧다.  

<img width="825" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/93ded7d2-4074-434d-b757-e69f6964b639">

B의 흐름이 A보다 오래 걸린다. 결과적으로 파드는 종료 신호를 보낸 후에도 클라이언트 요청을 받을 수 있다.  
애플리케이션이 서버 소켓을 닫고 연결 수락을 즉시 중지하면 클라이언트가 Connection Refused의 오류를 수신하게 된다.  

#### 문제해결

* 몇 초를 기다린 후, 새 연결을 받는 것을 막는다
* 요청 중이 아닌 모든 연결 유지 연결(keep-alive connections)을 닫는다
* 모든 활성 요청이 완료될 때까지 기다린다
* 그런 다음 완전히 셧다운한다

<img width="816" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/e75393b2-1008-45d0-8792-dfd6b563ef35">

---

