# 클러스터와 노드 구성

엘라스틱서치가 시대에 앞서갈 수 있는 이유는 클러스터에 속한 여러 노드에 필요한 작업을 나눠서 수행하는 분산 처리를 지원하여 엄청나게 큰 데이터를 다룰 수 있었기 때문이다.  

* 노드: 엘라스틱서치에서 클러스터를 구성하는 요소
* 클러스터: 여러 노드의 집합, 노드는 엘라스틱서치가 설치되는 물리적 혹은 논리적 단위  

<br/>

## HTTP 계층과 전송 계층

클러스터의 여러 노드들은 서로 통신을 하며 클러스터를 구성하고 있다.  
2가지 통신 모듈이 있다. 하나는 클러스터 내부에서 사용하는 전송 모듈이고 다른 하나는 외부와 통신에 사용되는 HTTP 모듈이다.  

* 전송 모듈
  * 클러스터 내부 모듈 간의 통신에 사용
  * 노드 간 데이터를 분산 처리하는 구조에 적합한 방식
  * 기본 포트: 9300 ~ 9399
* HTTP 모듈
  * 엘라스틱 API에서 제공하는 형태로 외부 클라이언트 앱과 통신 시 사용함
  * 기본 포트: 9200 ~ 9299

<br/>

## 노드

노드는 클러스터를 구성하는 하나의 인스턴스, 일반적으로 하나의 논리적인 서버로 구성되어 데이터를 저장하고 클러스터의 인덱싱과 검색 기능에 참여한다. 물리적인 서버 하나에 노드 하나를 구성하는 방식을 권장하지만, 단일 서버에 복수의 노드를 설치할 수도 있다.  

클러스터 참여 노드 이름은 중복 X, 하나의 노드가 여러 역할을 할 수도 있다. 하드웨어 영향을 많이 받는다.  

### 마스터 노드

클러스터는 최소 1개의 마스터 노드를 가져야 한다. 인덱스의 설정, 매핑 정보와 물리적 위치, 이 외에도 클러스터 설정 정보나 인덱스 템플릿 정보 등 클러스터의 모든 상태 정보를 관리한다. 각 노드들과 통신하면서 클러스터의 변화를 모니터링한다. 마스터 노드가 없으면 클러스터가 멈춘다. 사용자가 정할 수 없고 사용자는 마스터 노드의 후보만 지정할 수 있다.  

각 후보들이 후보들 중에서 어떤 노드가 마스터 노드가 될 것인지를 투표하고, 과반수가 되면 투표가 마무리 된다. 기존의 마스터 노드가 문제가 발생해 마스터 노드에서 이탈할 경우 나머지 후보 노드들 중에서 다시 뽑게된다.  

투표 전용 노드도 있다. 만약 노드 a,b,c가 있고 후보는 a,b고 b가 마스터로 뽑힌 상황일 때, b가 문제가 생기면 후보를 다시 뽑아야 하는데 후보가 a 밖에 없어서 마스터를 뽑을 수 없고 마스터가 없으니 클러스터가 멈출 것이다. 이런 경우를 대비해 c를 마스터 후보는 아니지만 투표는 가능한 노드로 두는 것이다.  

### 데이터 노드

데이터 노드는 인덱싱한 도큐먼트를 샤드 형태로 저장하여 데이터의 CRUD 작업과 검색 집계 작업을 한다.  
실질적인 데이터 프로세싱 작업이 일어나기 때문에 일반적으로 노드 중 가장 많은 부하를 받는다. 따라서 마스터 노드와 데이터 노드 역할을 구분하는 방식도 좋다. 데이터 노드의 부하로 인해 마스터 노드의 성능이 떨어질 경우 클러스터 전체의 안전성에 영향을 미치기 때문이다. 마스터 노드는 클러스터의 상태만 관리하고 데이터 노드는 데이터 처리만 하는 것이 좋다.  

데이터 노드는 컴퓨터 리소스(I/O, CPU, 메모리 등) 사용량에 민감하기 때문에 모니터링하면서 부하 상태를 체크하고 상황에 맞춰 명시적으로 샤드를 재분배하거나 데이터 노드를 추가/변경하는 작업을 해야 한다.  

### 인제스트 노드

인제스트 노드는 도큐먼트의 가공과 정제를 위한 인제스트 파이프라인이 실행되는 노드다. 인제스트 노드는 파이프라인을 통해 도큐먼트를 엘라스틱서치에 인덱싱하기 전에 원하는 형태로 변형할 수 있다. 로그스태시의 필터와 기능적으로 유사하나, 실행 주체가 엘라스틱서치라는 점과 지원되는 기능에 일부 차이가 있다. 무엇보다 로그스태시 설치 없이 비츠만 설치해 데이터를 수집하고, 인제스트 파이프라인을 이용해 이를 가공할 수 있다. 가볍고 간단한 수집 프로세스라면 비츠 + 인제스트 노드 조합, 좀 더 무겁고 복잡한 가공이 필요하다면 로그스태시까지 이용!  

모든 노드는 기본적으로 인제스트 노드 역할 수행이 가능하지만, 데이터 가공을 많이 하는 시스템이면 별도의 인제스트 전용 노드를 구성하는 것이 좋다.  

인제스트 노드는 프로세서와 파이프라인이라는 구성요소를 갖고 있다. 프로세서는 로그스태시의 필터처럼 도큐먼트를 변형할 수 있는 기능적으로 구분되는 모듈이고, 파이프라인은 프로세서의 집합이다.  

### 파이프라인

파이프라인 생성은 REST API로 제공된다. 주요 파라미터인 description은 파이프라인에 대한 설명이고 processors는 파이프라인이 처리해야 할 프로세서들이다.  

```elm
PUT _ingest/pipeline/mypipe
{
	"description": "description",
	"processors": [
		{
			"set": {
				"field": "status",
				"value": "low",
				
				"on_failure": [
					{
						"set": {
							"field": "error",
							"value": "set processor error"
						}
					}
				]
			}
		}
	],
	"on_failure": [
		{
			"set": {
				"field": "error",
				"value": "pipeline1 error"
			}
		}
	]
}
```

mypipe라는 파이프라인을 생성하고 set이라는 프로세서를 만든다. set은 값이 있다면 low를 할당 없다면 새로 만든다. 예외 처리 시에 on_failure를 사용하는데 프로세서 내부에 정의하면 프로세서 동작 중 발생하는 예외에 대한 처리이고, 파이프라인에 포함되어 있다면 파이프라인에서 발생하는 오류에 대한 예외를 처리한다.  

```elm
PUT my_index/_doc/1?pipeline=mypipe
{
	"name": "id1",
	"status": "high"
}
```

파이프라인인 mypipe를 이용해 도큐먼트를 인덱싱해보았다. 저장된 값을 보면 status가 low인 것을 확인할 수가 있을 것이다.  

```elm
PUT my_index2/_doc/1
{
	"name": "id1",
	"status": "high"
}

Put my_index2/_doc/2
{
	"name": "id2"
}
```

위와 같은 새로운 인덱스에서 파이프라인을 적용해서 수정해보려면 다음과 같이 수행하면된다.  

```elm
POST my_index2/_update_by_query?pipeline=mypipe
```

update API의 _update_by_query라는 API를 사용했다.  status가 low가 되었을 것이다.  

```elm
POST _reindex
{
	"source": {
		"index": "my_index2"
	},
	"dest": {
		"index": "my_index3",
		"pipleline": "mypipe"
	}
}
```

기존의 인덱스가 리인덱싱되면서 my_inde3이라는 새로운 인덱스를 생성하고 모든 도큐먼트가 새로운 인덱스 도큐먼트에 복사되는 과정에서 dest에 명시해준 파이프라인의 영향을 받는다. 수정해야 하는 도큐먼트가 많다면 update API를 사용해 도큐먼트를 일일이 수정하는 대신 리인덱싱과 파이프라인을 조합해 새로운 인덱스를 생성하는 방식이 성능상 유리할 수도 있다.  

**업데이트는 내부적으로 검색, 해당 도큐먼트 삭제, 수정된 도큐먼트 리인덱싱의 순서로 작업이 일어나는데, 삭제된 도큐먼트는 세그먼트 머지가 발생하기 전까지 ID만 내부적으로 기록해뒀다가 검색 시 필터링하는 방식이어서 검색 성능에 나쁜 영향을 미친다.**  

```elm
PUT my_index4
{
	"settings": {
		"default_pipeline": "mypipe"
	}
}
```

인덱스 설정에서 기본 파이프라인을 적용한 것이다. 해당 인덱스에 도큐먼트를 인덱싱하면 set 프로세서에 의해 status 필드가 추가되거나 수정된다.  

### 프로세서

앞에서 set을 사용했는데 https://www.elastic.co/guide/en/elasticsearch/reference/7.10/ingest-processors.html 이곳에서 종류를 살펴보자.  

간단한 종류와 예시  

* date: 날짜/시간 데이터를 파싱한다

```elm
{
	"date": {
		"field": "my_field",
		"target_field": "timestamp",
		"formats": ["dd/MM/yyyy hh:mm:ss"]
	}
}
```

my_field 필드에 있는 데이터가 포맷에 있는 날짜/시간 포맷일 경우 timestamp 날짜 객체에 저장한다.  

* drop: 특정 도큐먼트를 저장하고 싶지 않을 때 사용한다. 주로 "if" 옵션을 이용해 조건을 지정한다.  

```elm
{
	"drop": {
		"if": "ctx.my_field == 'Guest'"
	}
}
```

* grok: 고수준의 정규식 패턴인 grok를 이용해 특정 필드를 구조화된 필드들로 만들 수 있다.
* set: 생략
* split: 필드를 구분 기호를 이용해 분리한다. 분리된 필드는 배열 형태의 값을 갖는다.

```elm
{
	"split": {
		"field": "my_field",
		"separator": ","
	}
}
```

if, tag, on_failure 라는 공통의 파라미터를 이용해 더욱 재밌게 구성할 수 있다.  

```elm
PUT _ingest/pipeline/myproc
{
	"processors": [
		{
			"set": {
				"if": "ctx.name == 'id2'",
				"field": "status",
				"value": "low"
			}
		}
	]
}
```

이렇게 조건을 준 경우에만 set 프로세서가 돌아가게끔 말이다.  

### 그 밖의 노드들

머신러닝 노드,  
코디네이터 노드: REST API 요청을 처리하는 역할을 하고 모든 노드가 코디네이터 노드 역할을 수행할 수 있다. 사용자 요청 작업을 받아서 각 노드들에 전달하고 취합해 결과를 제공하는 역할을 한다.  
처리해야 하는 요청이 많거나 무거운 집계를 돌리는 경우 코디네이터 노드에서 연산 결과를 취합하는 과정에 리소스가 많이 필요하고 이 과정에서 다른 중요한 작업을 놓치기도 한다. 마스터 노드의 역할을 하고 있다면 더욱 문제가 될 수 있다. 따라서 데이터 코디네이터 작업이 많은 서비스의 경우 전용 코디네이터 노드를 두어 데이터 노드의 부하를 줄이고 검색 효율을 높이는 것이 좋다.  

### 전용 노드

노드는 별도의 설정이 없으면 모두 마스터 후보 노드이면서 데이터 노드, 인제스터 노드 등의 역할을 할 수 있다.  하지만 앞서 말했듯이 각자의 역할을 맡는 노드를 두는 것이 안전성에 좋다.  

노드의 역할을 변경하기 위해서는 elasticsearch.yml에 ``node.roles: [ 값 ]``  을 부여하면 된다.  

* 마스터 전용 노드: node.roles: [ master ]
* 투표 전용 노드: node.roles: [ master, voting_only ]
* 데이터 전용 노드: node.roles: [ data ]
* 인제스트 전용 노드: node.roles: [ ingest ]
* 머신러닝 전용 노드: node.roles: [ ml ]
* 코디네이터 전용 노드: node.roles: [  ]

전용 노드 권장 하드웨어 사양  

|                       | CPU    | 메모리    | 저장장치 |
| --------------------- | ------ | --------- | -------- |
| 마스터 후보 전용 노드 | 저사양 | 저사양    | 저사양   |
| 데이터 전용 노드      | 고사양 | 고사양    | 고사양   |
| 인제스트 전용 노드    | 고사양 | 중간 사양 | 저사양   |
| 코디네이터 전용 노드  | 저사양 | 중간 사양 | 저사양   |

<br/>

## 노드 구성과 시스템 구성

마스터 후보 전용 노드는 가능하면 1,3,5,7 같은 홀수 배열로 구성하며 나머지 노드들은 하트비트 같은 도구를 통해 주기적으로 상태 검사를 수행해 문제 여부를 판단하고 빠르게 복구할 수 있는 구조로 시스템을 구성하는 것이 중요하다.

### 소규모 클러스터

3~5대 정도의 노드가 있는 클러스터. 노드 개수가 부족해서 다양한 전용 노드를 구성하기는 힘들다. 5개를 사용한다는 가정 하에 말하겠다. 마스터 노드는 반드시 필요하므로 3개 정도를 마스터 후보 노드로 지정한다. 투표를 과반수 공식을 따르기 때문에 짝수가 아닌 홀수개로 둔 것이다. 데이터 노드는 많은 리소스를 필요로 하기 때문에 가능한 데이터 노드는 많을수록 좋다. 5개를 모두 데이터 노드로 구성한다면, 마스터 후보 노드들은 마스터 노드와 데이터 노드 역할을 같이 하기 때문에 하드웨어 구성에 좀 더 신경을 쓰고 시스템 부하를 모니터링하면서 데이터 노드를 확장할 수 있도록 준비해야 한다.  

### 대규모 클러스터

대규모 클러스터는 노드들을 효율적으로 관리하기 위해 전용 노드를 잘 활용하는 것이 중요하다. 마스터 후보 노드들은 하드웨어 성능은 비교적 중요하지 않지만 최소 3대를 준비하고 가능한 한 클라이언트의 요청을 받지 않도록 구성한다. 데이터 전용 노드는 온전히 데이터 작업만 진행하고 클러스터에서 가장 많이 배치해야 한다. 그리고 가능하면 고사양의 하드웨어를 구성하고 사양은 통일하는 것이 좋은데, 그 이유는 분산 처리 시 복수의 노드에서 발생한 결과를 코디네이터 노드에서 취합해야 하는데 데이터 노드 하나의 응답이 느리면 전체 응답 속도에 영향을 미치기 때문이다. 인제스트 전용 노드는 데이터 수집의 엔트리 포인트 역할로서, 특히 파이프라인을 이용한 데이터 정제 작업에 집중한다. 코디네이터 전용 노드는 검색이나 집계 작업 취합을 담당하는데, 서비스 성격에 따라 도입 유무를 결정하면 된다.  

마스터 노드의 불안정은 클러스터 전체의 불안정으로 이어지므로 마스터와 데이터 노드는 되도록 역할을 분리하고, 마스터 노드는 클라이언트의 요청이나 데이터 작업에 참여하지 않고 클러스터 관리에 집중시키는 것이 좋다.  

### 핫/웜/콜드 노드 구성

데이터 노드는 저장하는 데이터의 성격에 따라 핫/웜/콜드 노드로 구분가능하다. 데이터 노드를 더 효율적으로 사용해 전반적인 클러스터 효율을 높이기 위함이다.  

* 핫 노드: 활발하게 인덱싱과 검색이 일어나는 인덱스들을 위치시키고, 충분한 리소스의 하드웨어를 할당시켜준다.
* 웜 노드: 자주 사용하지 않는 데이터를 저장, 쿼리의 빈도가 낮고 인덱싱은 일어나지 않는 인덱스들이 해당된다. 핫 노드에 비해 성능 좋은 디스크나 큰 메모리는 필요없지만 많은 데이터를 저장하기 위해 대용량 디스크를 사용한다.
* 콜드 노드: 프리즈 모드의 인덱스들을 저장한다. 프리즈 모드의 인덱스는 평상시에는 메모리에 띄워놓지 않으므로 인덱스를 유지하기 위한 메모리 공간이 필요하지는 않으나, 검색 요청이 올 때 인덱스 파일을 오픈하기 때문엠 검색 시간이 많이 소요된다. 주로 검색을 수행하지는 않지만 데이터 보존 기간 정책상 보관해야만 하는 데이터들이 이에 해당된다. 

이 구성은 샤드 할당 필터링 기술이나 데이터 티어를 사용한다. 샤드 할당 필터링은 샤드를 조건에 따라 특정 노드에 저장하는 방법이고 데이터 티어는 7.10 버전에 추가된 기능으로 하드웨어가 동일한 노드들을 묶는 방법이다.  

샤드를 필터링하는 방법은 노드를 핫/웜 이런 식으로 속성을 달고 인덱스의 사용빈도에 따라 적절한 노드에 저장하는 식이다.  

속성 태그를 다는 법은 노드의 elasticsearch.yml에 ``node.attr`` 속성을 이용하는 것이다.  ``node.attr.node_tag: hot``  
그 뒤에 속성값과 태그명을 적는 것이다. 위의 예시는 node_tag라는 이름의 속성을 만들고 hot이라는 이름의 태그를 단 것이다.  

이제 인덱스 설정에 샤드 필터링을 추가해보자.  

```elm
PUT sample_data_now
{
	...
	"settings": {
		"index.routing.allocation.require.node_tag": "hot"
	}
}
```

``index.routing.allocation.require``는 샤드 필터링 조건을 정의하기 위한 파라미터다. 이제 이 인덱스는 속성과 태그값이 일치하는 특정 노드에만 저장된다.  

사용 빈도가 떨어진 인덱스가 있어 핫에서 웜이나 콜드로 옮겨야 하는 경우 다음과 같이 한다.  

```elm
PUT sample_data_yesterday/_settings
{
	"index.routing.allocation.require.node_tag": "warm"
}
```

sample_data_yesterday 인덱스를 ``note_tag: warm`` 으로 태깅되어 있는 노드로 이동하는 요청이다.  
이렇게 인덱스를 사이클에 맞춰 노드를 옮겨주면 시스템 효율성 측면에서 이롭다. 엘라스틱서치의 ILM(Index Lifecycle Management)를 통해 노드를 이동하고 관리받을 수도 있다. 키바나 메뉴의 Management > Stack Management > Index Lifecycle Management 를 확인해보자.  

<br/>

## 클러스터 백업

엘라스틱서치는 백업을 위해 스냅샷을 지원한다. 스냅샷을 위한 저장소는 repository라고 하는데 스냅샷을 찍기 전에 먼저 repository부터 지정해야 한다.  

### repository 등록

```elm
PUT _snapshot/fsrepo
{
	"type": "fs",
	"settings": {
		"location": "C:\\elasticsearch-7.10.1"
	}
}
```

snapshot api를 이용했다. type에 따라 사용법이 달라진다. 위의 경우는 파일시스템(fs) 이고, 빅데이터 파일시스템(HDFS), 아마존(s3), 마이크로소프트 애저(azure) 등이 있다. [링크참고](https://www.elastic.co/guide/en/elasticsearch/reference/7.10/snapshots-register-repository.html#snapshots-filesystem-repository)  

repository는 클러스터를 구성하는 마스터 노드와 데이터 노드가 동일한 위치를 공유해야 하기 때문에 노드 설정 파일에서 repository 경로를 지정해야 한다.  

```elm
path.repo: "C:\\elasticsearch-7.10.1"
```

각 노드의 elasticsearch.yml에 ``path.repo`` 를 이용하여 위치를 지정해주자.  

### 스냅샷 찍기

이제 스냅샷을 찍어야 하는데 이 또한 API가 제공이되며 스냅샷을 찍는 시각의 모든 데이터를 복사해서 데이터를 저장한다.  
이후에 다시 스냅샷을 찍으면 변경된 부분만 스냅샷에 기록한다.  

```elm
GET _snapshot 
// 현재 등록된 repository 확인

PUT _snapshot/fsrepo/snapshot1
// snapshot1 의 이름으로 스냅샷을 요청했다. 스냅샷은 fsrepo repository에 저장된다. 인덱스를 지정하지 않으면 클러스터 내의 모든 인덱스의 스냅샷을 찍는다. 특정 인덱스만 스냅샷을 찍을 수도 있다.

PUT _snapshot/fsrepo/snapshot2
{
	"indices": "kibana_sample_data_*",
	"ignore_unavailable": true
}
```

indices에 스냅샷을 찍을 인덱스를 둔다. 배열 형태도 가능하고 위 처럼 와일드카드를 이용할 수도 있다.  
ignore_unavailable은 비활성화된 인덱스는 스냅샷을 찍지 않는다는 뜻이다. 운영 모드에서 리소스의 효율적 사용을 위해서 사용하지 않은 인덱스들은 비활성화하는데 이런 인덱스들은 스냅샷에서 걸러진다.  

### 스냅샷 복원

스냅샷 복원을 위해 restore API를 제공한다. 모든 인덱스를 가져와보겠다.  

```elm
POST _snapshot/fsrepo/snapshot1/_restore
```

하지만 현재 클러스터에 index1 이라는 인덱스가 있고 repository에도 동일한 이름의 인덱스가 있다면 복원되지 않는다. 지우거나 이름을 변경해야 한다.  

```elm
POST _snapshot/fsrepo/snapshot1/_restore
{
	"indices": "kibana_sample_data_*",
	"ignore_unavailable": true,
	"rename_pattern": "kibana_sample_data_(.+)",
	"rename_replacement": "restored-kibana_sample_data_$1"
}
```

indices에 적힌 인덱스를 ignore_unavailable true로 (앞에서 설명함) rename_pattern은 변경하려는 인덱스의 이름이고 rename_replacement는 변경되는 인덱스의 이름이다.  

스냅샷을 찍어도 변경사항만 적용되므로 용량이 크게 늘어나지 않는다. 따라서 자주 찍어주는 방식을 권장한다.  
스냅샷 수명주기를 관리하는 기능인 SLM(Snapshot Lifecycle Management)이 스냅샷 빈도나 관리를 자동화해줄 수 있다.  

<br/>

## 샤드

도큐먼트를 인덱스에 저장한다고 하지만 인덱스는 가상의 논리적 단위이며 실제 도큐먼트의 인덱싱과 검색은 샤드에서 일어나게 된다.  
my_index라는 인덱스가 있고 샤드를 5개 만들고, 클러스터에 노드가 3개가 있다고 가정하자.  그러면 도큐먼트는 5개의 샤드 중 하나에 저장된다. 이때 코디네이터 노드, 즉 최초 요청을 수신한 노드는 문서에 별도의 ID가 주어지지 않는다면 랜덤  ID를 생성하며, _routing 파라미터가 명시되지 않았다면 ID를 이용해 도큐먼트가 인덱싱될 샤드를 결정한다.  

```elm
shard = hash(_routing) & 프라이머리 샤드 개수 
// 샤드를 선택하는 공식
```

도큐먼트가 어떤 샤드에 저장되는지 결정하는 것을 라우팅이라고 한다.  

### 프라이머리 샤드와 레플리카 샤드

인덱스를 샤드 단위로 나누어 노드들에 분산 저장하고 있으므로 노드 하나만 클러스터를 이탈해도 데이터 손실이 어마어마할 것이다. 이를 위해 엘라스틱서치는 데이터의 원본을 프라이머리 샤드에 저장하고 복제본인 레플리카 샤드를 만들어 사용한다.  

```elm
PUT index
{
	"settings": {
		"number_of_shards": 3,
		"number_of_replicas": 2
	}
}
```

위에서 샤드가 3, 레플리카가 2개다. 그러면 총 9개의 샤드가 있는 것이다. 원본 당 레플리카가 2개씩이니 (원본 + 레플리카 수) * 샤드 수  
명시하지 않으면 샤드, 레플리카 각 1씩이다.  

레플리카 샤드는 시스템의 안전성 뿐만 아니라 성능 향상도 가져온다.  
일단 당연히 노드가 죽어도 레플리카가 있기 때문에 가용성이 높다. 프라이머리 샤드가 죽으면 레플리카를 프라이머리로 사용하게 된다.  

그리고 레플리카 샤드 또한 클라이언트의 요청을 수행할 수 있다. 따라서 처리 부하를 분산시켜 성능을 향상하는 효과를 줄 수 있다. 어떤 노드가 부하가 걸려 반응이 느리다면 좀 더 빠른 검색을 위해 다른 노드에 있는 레플리카 샤드를 이용해서 처리하는 등 성능의 안정성에도 기여한다.  

### 샤드 할당 과정

과정은 크게 미할당(UNASSIGNED), 초기화(INITIALIZING), 동작(STARTED), 재할당(RELOCATING) 으로 나뉜다.  

UNASSIGNED: 샤드는 있지만 아직 노드에 할당되지 않은 상  

INITIALIZING: 샤드를 노드에 로딩 중인 상태, 노드에 샤드가 추가된 상태이지만 아직 메모리에 온전하게 적재된 것은 아니라서 샤드 사용이 불가능, 마스터 노드는 데이터 노드들 중에서 샤드를 생성할 수 있는 노드를 찾고 할당이 가능한 노드부터 프라이머리 샤드를 적재하기 시작한다.  

STARTED: 샤드가 메모리에 올라간 상태로 이 상태에서만 샤드에 접근 가능하다. 프라이머리 샤드가  STARTED 상태가 되면 레플리카 샤드가 할당된다. 레플리카 샤드도 INITIALIZING -> STARTED 상태를 거치게 된다.  

RELOCATING: 샤드가 재배치되는 단계, 분산 환경의 시스템에서 노드가 추가되거나 삭제될 시에 샤드 역시 재배치가 필요하다. 노드가 추가되면 다른 노드에서 하나가 옮겨가고, 노드가 삭제되고 내부에 프라이머리 샤드가 있다면 레플리카 샤드 하나를 프라이머리로 바꾸고 레플리카 샤드를 하나 새롭게 할당하게된다.  

샤드 상태를 모니터링 하기 위해서는 ``GET _cat/shard?v`` 를 이용한다.  
``GET _cat/indices?v`` 를 통해서 인덱스의 상태를 확인할 수 있는데 인덱스 상태가 red, yellow, green으로 나뉘고 이것들은 샤드의 이상 유무와도 같다.  

* red: 하나 이상의 프라이머리 샤드가 클러스터에 정상적으로 적재되지 않았다. 데이터 읽기/쓰기가 정상적으로 동작하지 않는다.
* yellow: 프라이머리 샤드는 모두 적재되었지만 하나 이상의 레플리카 샤드가 정상적으로 적재되지 않았다. 인덱스를 읽고 쓰는 것은 문제없지만 레플리카 샤드가 없으면 장애 발생 시 해당 인덱스에 대한 서비스가 불가능할 수 있다.
* green: 모두 정상적으로 적재되었다.

red나 yellow 일 때에는 클러스터를 재배치하거나 시스템을 재가동하는 식으로 작업을 진행한다.  

<br/>

## 샤드 개수와 크기 구성 가이드

### 샤드 개수 가이드

프라이머리 샤드가 너무 많으면 오버샤딩 문제를 발생시킬 가능성이 있다. 오버샤딩은 샤드를 잘게 나누어 필요 이상의 많은 리소스를 사용하게 하는 문제다. 2개의 노드에 10GB 인덱스를 만드는데 프라이머리 샤드가 10개면 각 샤드의 크기가 1GB로 너무 작고 노드 수에 비해 샤드가 너무 많다.  

1. 샤드는 개별적으로 리소스를 소비한다. cpu, memory, 루씬 인스턴스 등... . 즉, 샤드가 많을수록 시스템 성능에는 좋지 않다.  
2. 인덱스 검색을 위해 인덱스가 저장된 모든 샤드에 접근해야 한다. 10개의 샤드에 접근해야하므로 많은 리소스를 낭비하게 된다. 

샤드 수가 무조건 적어야 하는 것도 아니다. 샤드 수가 많으면 그만큼 분산/병렬 처리에는 좋다. 공식적으로 권장하는 방법은 실 데이터를 가지고 샤드 수를 조정하며 벤치마크 하는 것이다.  

### 샤드 크기 가이드

샤드 크기 또한 너무 크면 성능 문제가 발생하고 샤드가 너무 작으면 담을 수 있는 도큐먼트가 작아진다는 문제가 있따. 엘라스틱에서는 통계적으로 볼 때 샤드 하나의 크기가 10~40GB 정도로 관리하는 것이 좋다고 권고한다.  

도큐먼트를 무한정 집어넣다보면 샤드의 크기는 커질 수밖에 없고 성능 문제가 발생한다. 따라서 인덱스 크기가 조건을 넘어서면 인덱스를 분리하는 식이다. 요즘은 ILM(Index Lifecycle Management)을 통해 인덱스를 관리하는데, rollover API와  shrink API를 이용해서 관리해보겠다.  

```elm
PUT rollover-000001
{
	"aliases": {
		"rollover-alias": {
			"is_write_index": true
		}
	}
}
```

rollover API는 인덱스가 특정 조건에 도달했을 때 새로운 인덱스를 생성하는 API다. 이를 통해 인덱스의 크기를 일정하게 유지할 수 있지만 요청이 있을 경우에만 발생하기 때문에 요청 전에는 샤드 크기가 아무리 커져도 새로운 인덱스가 생성되지 않는다. 자동적으로 조건을 체크하고 새로운 인덱스를 생성하는 기능은  ILM이 제공한다.  

rollover-00001 이라는 인덱스를 생성한거고 별칭을 rollover-alias로 정한 것이다. 여러 인덱스를 그룹핑 할 수 있게 됐다. 여러 인덱스에 이름이 같은 별칭을 추가할 수 있지만 별칭이 같은 인덱스 중 단 하나의 인덱스만이 쓰기 권한을 가질 수 있다. 그것을 true로 해서 설정한 것이다. 별칭을 사용하는 인덱스 이름은 반드시 '-숫자' 형태로 끝나야 한다.  

```elm
POST rollover-alias/_rollover
{
	"conditions": {
		"max_age": "30d",
		"max_docs": 1,
		"max_size": "50gb"
	}
}
```

conditions(조건)을 정하고 그 조건에 맞을 경우 새로운 인덱스를 생성한다.  

* max_age: 인덱스가 생성되고 경과된 시간
* max_docs: 인덱스 도큐먼트의 최대 개수
* max_size: 인덱스 최대 크기

만약 조건에 맞다면 rollover-00002 인덱스가 생성될 것이다. 이제 쓰기는 이 인덱스가 맡게 되고, 읽기는 모든 인덱스가 참여하게 된다.  

shrink API는 기존 인덱스의 프라이머리 샤드 개수를 줄이는 데 사용한다. 핫 노드에서 웜 노드로 이동하는 인덱스에도 사용할 수 있다. 자주 사용하지 않는 인덱스의 샤드는 많을 필요가 없기 때문이다.  

```elm
PUT shrink-1
{
	"settings": {
		"number_of_shards": 3,
		"number_of_replicas": 2
	}
}

PUT shrink-1/_settings
{
	"index": {
		"number_of_replicas": 0,
		"routing.allocation.require._name": "shrink_node_name",
		"blocks.write": true
	}
}

POST shrink-1/_shrink/shrink-1-target
{
	"settings": {
		"index.number_of_shards": 1,
		"index.number_of_replicas": 1,
		"index.routing.allocation.require._name": null,
		"index.blocks.write": null,
		"codec": "best_compression"
	}
}
```

프라이머리 샤드 3개, 레플리카 샤드 2개인 shrink-1 라는 인덱스를 먼저 만들고(1개/1개 면 shrink 사용을 할 수가 없으니), 다시 세팅을 레플리카를 0개로(어차피 shrink 후에 합쳐진 프라이머리 샤드를 기준으로 새로운 레플리카 샤드를 생성하기 때문에 샤드의 이동을 빠르게 하기 위해 레플리카 샤드를 임시로 비활성화 한 것임) 그리고 ``routing.allocation.require._name`` 을 통해 모든 샤드가 ``shrink_node_name`` 이라는 노드로 옮겨지게 된다. shrink 진행 중 새로운 도큐먼트의 인덱싱을 방지하기 위해 write를  block 해놓았다.  

shrink API를 통해 shrink-1 인덱스를  shrink-1-target 인덱스로 변경한다. 필드에 정의한 대로 1개의 샤드 1개의 레플리카만 가질 것이고 best_compression 코덱을 적용해 저장소를 좀 더 적게 사용하도록 했다. 쓰기 block과 ._name을 null로 둬서 다시 인덱스가 클러스터 전반에 고루 분배되도록 했다.  
***
