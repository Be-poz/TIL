# 엘라스틱서치: 집계

엘라스틱서치에서 집계는 데이터를 그룹핑하고 통곗값을 얻는 기능으로 SQL의 GROUP BY와 통계 함수를 포함하는 개념이다.  


## 집계의 요청-응답 형태

```elm
GET <인덱스>/_search
{
  "aggs": {
    "my_aggs": {
      "agg_type": {
	...
      }
    }
  }
}

{
  ...
  "hits": {
    "total": {
      ...
    }
  },
  "aggregations": {
    "my_aggs": {
      "value":
    }
  }
}
```

aggs 라는 파라미터를 이용해서 집계 요청을 할 수가 있다. ``my_aggs`` 는 사용자가 지정하는 집계이름이다. ``agg_type`` 은 집계 타입을 의미한다. 집계 타입은 크게 2가지 타입의 집계가 있다.  

* 메트릭 집계: 통계나 계산에 사용된다.
* 버킷 집계: 도큐먼트를 그룹핑하는 데 사용된다.

응답 형태는 ``aggregations`` 에 집계 요청에 대한 결과가 들어있다. 사용자가 지정한 집계이름 안의 ``value`` 에 결과가 들어있다.  

<br/>

## 메트릭 집계

메트릭 집계는 필드의 최소/최대/합계/평균/중간값 같은 통계 결과를 보여준다.  

**메트릭 집계 종류**  

* avg: 필드의 평균값을 계산한다
* min: 필드의 최솟값을 계산한다
* max: 필드의 최댓값을 계산한다
* sum: 필드의 총합을 계산한다
* percentiles: 필드의 백분윗값을 계산한다
* stats: 필드의 min, max, sum, avg, count(도큐먼트 개수)를 한 번에 볼 수 있다
* cardinality: 필드의 유니크한 값 개수를 보여준다
* geo-centroid: 필드 내부의 위치 정보의 중심점을 계산한다

```elm
// REQUEST
get kibana_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "stats_aggs": {
      "avg": {
        "field": "products.base_price"
      }
    }
  }
}

// RESPONSE
{
  "took" : 2,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 4675,
      "relation" : "eq"
    },
    "max_score" : null,
    "hits" : [ ]
  },
  "aggregations" : {
    "stats_aggs" : {
      "value" : 34.88652318578368
    }
  }
}
```

평균값을 요청했다. ``"size": 0`` 을 하면 응답의 hits에 집계에 사용한 도큐먼트를 결과에 포함하지 않아 비용을 절약할 수 있게 된다.  

```elm
get kibana_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "stats_aggs": {
      "percentiles": {
        "field": "products.base_price",
        "percents": [
          25,
          50
        ]
      }
    }
  }
}
```

base_price 백분율의 25%, 50% 에 속하는 데이터를 요청. 중간값은 50, 최댓값은 100이다.  

```elm
get kibana_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "cardi_aggs": {
      "cardinality": {
        "field": "day_of_week",
        "precision_threshold": 100
      }
    }
  }
}
```

``day_of_week`` 필드의 유니크한 데이터 개수를 요청했다. ``precision_threshold`` 는 정확도 수치라고 보면된다. 값이 크면 정확도가 올라가는 대신 시스템 리소스를 많이 소모하고, 값이 작으면 정확도는 떨어지는 대신 시스템 리소스를 덜 소모한다.  

이 값을 100이 아니라 5로 두면 부정확한 결과값이 나온다. 일반적으로 이 값은 카디널리티의 실제 결과보다 크게 잡아야 한다. 하지만 실제 결과를 모르기 때문에 값을 변경해보면서 값이 변경되지 않는 임계점을 찾는 것도 방법이다. 기본값은 3000이며, 최대 40000까지 값을 설정할 수 있다.  

```elm
get kibana_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "cardi_aggs": {
      "terms": {
        "field": "day_of_week"
      }
    }
  }
}
```

버킷 집계의 일종인 ``terms`` 를 사용하면 유니크한 필드 개수와 함께 필드값들을 확인할 수 있다.  

```elm
  "aggregations" : {
    "cardi_aggs" : {
      "doc_count_error_upper_bound" : 0,
      "sum_other_doc_count" : 0,
      "buckets" : [
        {
          "key" : "Thursday",
          "doc_count" : 775
        },
        {
          "key" : "Friday",
          "doc_count" : 770
        },
        {
          "key" : "Saturday",
          "doc_count" : 736
        },
        {
          "key" : "Sunday",
          "doc_count" : 614
        },
        {
          "key" : "Tuesday",
          "doc_count" : 609
        },
        {
          "key" : "Wednesday",
          "doc_count" : 592
        },
        {
          "key" : "Monday",
          "doc_count" : 579
        }
      ]
    }
  }
```

이런 식으로 응답된다.  

```elm
get kibana_sample_data_ecommerce/_search
{
  "size": 0,
  "query": {
    "term": {
      "day_of_week": "Monday"
    }
  },
  "aggs": {
    "query_aggs": {
      "sum": {
        "field": "products.base_price"
      }
    }
  }
}
```

위와 같이 작성하면 Monday로 먼저 쿼리를 치고 이후에 집계를 할 수가 있다.  

<br/>

## 버킷 집계

메트릭 집계가 특정 필드를 기준으로 통곗값을 계산하려는 목적이라면, 버킷 집계는 특정 기준에 맞춰서 도큐먼트를 그룹핑하는 역할을 한다.  
여기서 버킷은 도큐먼트가 분할되는 단위로 나뉜 각 그룹을 의미한다.  

**버킷 집계 종류**  

* histogram: 숫자 타입 필드를 일정 간격으로 분류한다
* date_histogram: 날짜/시간 타입 필드를 일정 날짜/시간 간격으로 분류한다
* range: 숫자 타입 필드를 사용자가 지정하는 범위 간격으로 분류한다
* date_range: 날짜/시간 타입 필드를 사용자가 지정하는 날짜/시간 간격으로 분류한다
* terms: 필드에 많이 나타나는 용어(값)들을 기준으로 분류한다
* significant_terms: terms 버킷과 유사하나, 모든 값을 대상으로 하지 않고 인덱스 내 전체 문서 대비 현재 검색 조건에서 통계적으로 유의미한 값들을 기준으로 분류한다
* filters: 각 그룹에 포함시킬 문서의 조건을 직접 지정한다. 이때 조건은 일반적으로 검색에 사용되는 쿼리와 동일하다

```elm
// REQUEST
get kibana_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "histogram_aggs": {
      "histogram": {
        "field": "products.base_price",
        "interval": 100
      }
    }
  }
}

// RESPONSE
"aggregations" : {
    "histogram_aggs" : {
      "buckets" : [
        {
          "key" : 0.0,
          "doc_count" : 4672
        },
        {
          "key" : 100.0,
          "doc_count" : 263
        },
        {
          "key" : 200.0,
          "doc_count" : 12
        },
        {
          "key" : 300.0,
          "doc_count" : 1
        },
        ...
      ]
    }
  }
```

필드값을 100 간격으로 구분했고 그에 따른 count 값이 응답된다.  

```elm
get kibana_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "range_aggs": {
      "range": {
        "field": "products.base_price",
        "ranges": [
          {"from": 0, "to": 50},
          {"from": 50, "to": 100},
          {"from": 100, "to": 200},
          {"from": 200, "to": 1000}
        ]
      }
    }
  }
}
```

``range`` 는 동일 범위만 지정할 수 있는 ``histogram`` 과는 다르게 사용자가 직접 설정할 수 있다.  

만약 ``products.base_price`` 가 배열 형태고 한 도큐먼트에서 이 값을 [20, 70] 이렇게 갖고 있으면 0~100 범위에서 이 값은 count가 1이되고,  
0~50, 50~100 이렇게 범위를 지정하게되면 각각 count가 돼서 총 count 결과값이 달라질 수 있다.  

```elm
get kibana_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "term_aggs": {
      "terms": {
        "field": "day_of_week",
        "size": 6
      }
    }
  }
}
```

``terms`` 는 메트릭 집계에서 다뤘는데 size 파라미터를 추가해봤다. 이 파라미터는 만들어지는 버킷 수를 지정하는데 해당 필드의 값을 기준으로 도큐먼트 수가 많은 상위 size 개의 버킷을 요청한다. 기본값은 10이다. 따라서 위의 결과는 요일 중 하나가 빠진 값이 나오게 된다.  

``terms`` 로 검색을 하면 결과 필드 중에 ``doc_count_error_upper_bound`` 가 있는 것을 확인할 수 있다.  
버킷이 잠재적으로 카운트하지 못할 도큐먼트의 수를 의미한다.  

용어 집계가 정확하지 않고 이런 부정확도를 표시하는 이유는 분산 시스템에서 데이터를 여러 노드에서 분산하고 취합하는 과정에서 오류가 발생할 수 있기 때문이다. 엘라스틱서치는 샤드에 도큐먼트를 저장하고 이를 분산하는데, size 설정값과 샤드 개수 등에 의해 집계에 오류가 발생할 수 있다.  

고속처리를 위한 리소스와 속도 간 트레이드오프의 일환으로 리소스 소비량을 늘리면 정확도를 높일 수 있다.  

```elm
"terms": {
	"fields": "day_of_week",
	"size": 6,
	"doc_count_error_upper_bound": true
}
```

``doc_count_error_upper_bound`` 파라미터를 추가해줌으로써 각 버킷마다 이 값을 확인할 수가 있다.  

```elm
"terms": {
	"fields": "day_of_week",
	"size": 6,
	"shard_size": 100
}
```

``shard_size`` 파라미터를 이용해 샤드 크기를 늘릴 수 윘따. 샤드 크기는 용어 집계 과정에서 개별 샤드에서 집계를 위해 처리하는 개수를 의미한다.  
샤드 크기를 크게 하면 정확도가 올라가는 대신 리소스 사용량이 올라가 성능은 떨어질 수 있다. 샤드 크기는 기본적으로 ``버킷의 개수 * 1.5 + 10`` 으로 계산된다.  

<br/>

## 집계의 조합

메트릭 집계와 버킷 집계를 조합해보겠다.  

```elm
// REQUEST
get kibana_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "term_aggs": {
      "terms": {
        "field": "day_of_week",
        "size": 5
      },
      "aggs": {
        "avg_aggs": {
          "avg": {
            "field": "products.base_price"
          }
        }
      }
    }
  }
}

// RESPONSE
  "aggregations" : {
    "term_aggs" : {
      "doc_count_error_upper_bound" : 0,
      "sum_other_doc_count" : 1171,
      "buckets" : [
        {
          "key" : "Thursday",
          "doc_count" : 775,
          "avg_aggs" : {
            "value" : 34.68040897713688
          }
        },
        {
          "key" : "Friday",
          "doc_count" : 770,
          "avg_aggs" : {
            "value" : 34.665464386512184
          }
        },
        {
          "key" : "Saturday",
          "doc_count" : 736,
          "avg_aggs" : {
            "value" : 34.35796178343949
          }
        },
        {
          "key" : "Sunday",
          "doc_count" : 614,
          "avg_aggs" : {
            "value" : 35.27872066570881
          }
        },
        {
          "key" : "Tuesday",
          "doc_count" : 609,
          "avg_aggs" : {
            "value" : 34.33571633511859
          }
        }
      ]
    }
  }
```

먼저 요일별로 버킷을 나누고 그 중 상위 5개의 버킷만 사용한다. 그리고 각각의 버킷 내부에서 ``avg_aggs`` 가 실행되게끔 해서 내부에 평균값이 응답된 것을 확인할 수가 있었다.  

```elm
get kibana_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "term_aggs": {
      "terms": {
        "field": "day_of_week",
        "size": 5
      },
      "aggs": {
        "avg_aggs": {
          "avg": {
            "field": "products.base_price"
          }
        },
        "sum_aggs": {
          "sum": {
            "field": "products.base_price"
          }
        }
      }
    }
  }
}
```

이런 식으로 ``sum`` 을 보고싶어서 복수 개의 메트릭 집계를 수행할 수도 있다.  

```elm
// REQUEST
get kibana_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "histogram_aggs": {
      "histogram": {
        "field": "products.base_price",
        "interval": 100
      },
      "aggs": {
        "term_aggs": {
          "terms": {
            "field": "day_of_week",
            "size": 2
          }
        }
      }
    }
  }
}

// RESPONSE
  "aggregations" : {
    "histogram_aggs" : {
      "buckets" : [
        {
          "key" : 0.0,
          "doc_count" : 4672,
          "term_aggs" : {
            "doc_count_error_upper_bound" : 0,
            "sum_other_doc_count" : 3128,
            "buckets" : [
              {
                "key" : "Thursday",
                "doc_count" : 775
              },
              {
                "key" : "Friday",
                "doc_count" : 769
              }
            ]
          }
        },
        {
          "key" : 100.0,
          "doc_count" : 263,
          "term_aggs" : {
            "doc_count_error_upper_bound" : 0,
            "sum_other_doc_count" : 176,
            "buckets" : [
              {
                "key" : "Friday",
                "doc_count" : 44
              },
              {
                "key" : "Thursday",
                "doc_count" : 43
              }
            ]
          }
        },
 ...
```

이렇게 버킷 안에서 다시 버킷 집계를 요청하는 집계를 사용할 수도 있다. 서브 버킷이라고 부른다.  
서브 버킷을 많이 만들수록 버킷의 수는 기하급수적으로 늘어날 수 있으므로 주의하자. 집계의 성능이 느려질 뿐만 아니라 클러스터에 과도한 부하를 가하게 될 수 있다.  

<br/>

## 파이프라인 집계

파이프라인 집계는 이전 결과를 다음 단계에서 이용하는 파이프라인 개념을 사용한다.  
엘라스틱 파이프라인 집계는 이전 집계로 만들어진 결과를 입력으로 삼아 다시 집계하는 방식이다.  
이 과정에는 부모 집계와 형제 집계라는 두 가지 유형이 있다. 두 집계의 가장 큰 차이점은 집계가 작성되는 위치다. 부모 집계는 기존 집계 내부에서 작성하고 형제 집계는 기존 집계 외부에서 새로 작성한다.  

```elm
// 부모 집계
// 기존 집계 결과를 이용해 새로운 집계를 생성한다. 결과는 기존 집계 내부에서 나온다.
{
  "aggs": {
    ...
    "aggs": {
      ...
      "부모 집계"
    }
  }
}

// 형제 집계
// 기존 집계를 참고해 집계를 수행한다. 결과는 기존 집계와 동일선상에서 나온다.
{
  "aggs": {
  ...
    "aggs": {
      ...
    }
  }
}
```

**파이프라인 집계 종류**  

* 형제 집계
  * min_bucket: 기존 집계 중 최솟값을 구한다
  * max_bucket: 기존 집계 중 최댓값을 구한다
  * avg_bucket: 기존 집계의 평균값을 구한다
  * sum_bucket: 기존 집계의 총합을 구한다
  * stat_bucket: 기존 집계의  min, max, sum, count, avg를 구한다
  * percentile_bucket: 기존 집계의 백분윗값을 구한다
  * moving_avg: 기존 집계의 이동 평균을 구한다. 단, 기존 집계는 순차적인 데이터 구조여야 한다
* 부모 집계
  * derivative: 기존 집계의 미분을 구한다
  * cumulative_sum: 기존 집계의 누적합을 구한다

```elm
// REQUEST
get kibana_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "histogram_aggs": {
      "histogram": {
        "field": "products.base_price",
        "interval": 100
      },
      "aggs": {
        "sum_aggs": {
          "sum": {
            "field": "taxful_total_price"
          }
        },
        "cum_sum": {
          "cumulative_sum": {
            "buckets_path": "sum_aggs"
          }
        }
      }
    }
  }
}

// RESPONSE
  "aggregations" : {
    "histogram_aggs" : {
      "buckets" : [
        {
          "key" : 0.0,
          "doc_count" : 4672,
          "sum_aggs" : {
            "value" : 348124.12890625
          },
          "cum_sum" : {
            "value" : 348124.12890625
          }
        },
        {
          "key" : 100.0,
          "doc_count" : 263,
          "sum_aggs" : {
            "value" : 44002.0
          },
          "cum_sum" : {
            "value" : 392126.12890625
          }
        },
        ...
```

부모 집계를 사용한 예시다. 부모 집계를 사용하기 위해서는 입력으로 다른 집계가 필요한데, 히스토그램 집계와 합계 집계를 먼저 사용했다.  
부모 집계는 합계 집계인  ``sum_aggs`` 를 입력으로 받아 최종적으로 각 버킷의 누적합을 구한다.  

```elm
// REQUEST
get kibana_sample_data_ecommerce/_search
{
  "size": 0,
  "aggs": {
    "term_aggs": {
      "terms": {
        "field": "day_of_week",
        "size": 2
      },
      "aggs": {
        "sum_aggs": {
          "sum": {
            "field": "products.base_price"
          }
        }
      }
    },
    "sum_total_price": {
      "sum_bucket": {
        "buckets_path": "term_aggs>sum_aggs"
      }
    }
  }
}

// RESPONSE
"aggregations" : {
    "term_aggs" : {
      "doc_count_error_upper_bound" : 0,
      "sum_other_doc_count" : 3130,
      "buckets" : [
        {
          "key" : "Thursday",
          "doc_count" : 775,
          "sum_aggs" : {
            "value" : 58020.32421875
          }
        },
        {
          "key" : "Friday",
          "doc_count" : 770,
          "sum_aggs" : {
            "value" : 58341.9765625
          }
        }
      ]
    },
    "sum_total_price" : {
      "value" : 116362.30078125
    }
  }
```

형제 집계를 이용했다. 부모 집계에서 이용한 누적합 집계와 다르게 '>' 를 이용해 경로의 하위 집계 경로를 나타낸다.  
그리고 기존 집계 내부가 아니라 외부에서 결과를 보여주며 모든 버킷에서 나온 값이 합산됐다.  
***
