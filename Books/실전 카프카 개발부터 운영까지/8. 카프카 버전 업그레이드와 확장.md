# 카프카 버전 업그레이드와 확장

카프카 버전을 업그레이드 하기 전에 어떤 것이 변경되었는지 확인해야한다. 특히 메이저 버전 변경인 경우 더더욱 그렇다.  
카프카의 상위 버전은 클라이언트들의 하위 호환성을 갖고 있으므로 대부분 클라이언트 이슈는 없다.  

롤링 업그레이드를 해보겠다(2.1 버전을 2.6 버전으로 업그레이드 하는 것을 예시로).  

```sh
2.6 버전 설치

# properties 복사
cd /usr/local
sudo cp kafka_2.12-2.1.0/config/server.properties kafka_2.12-2.6.0/config/server.properties
sudo vi kafka_2.12-2.6.0/config/server.properties

# 아래 설정을 properties에 추가, 다른 브로커들은 아직 2.1 버전이기 때문에 브로커 간의 내부 통신은 2.1 버전으로 하게끔 하기 위한 설정이다. 메세지 포맷도 2.1으로 한다는 뜻이다.
inter.broker.protocol.version=2.1
log.message.format.versions=2.1

# 카프카 중지
sudo systemctl stop kafka-server

# 기존의 심볼릭 링크인 kafka 삭제
sudo rm -rf kafka
# 2.6 버전으로 링크를 다시 걸음
sudo ln -sf kafka_2.12-2.6.0 kafka

# kafka 재가동
sudo systemctl start kafka-server
```

위의 과정을 브로커마다 실행해준다. 모두 업그레이드 한 이후에는 2.1 버전으로 브로커 간의 내부 통신을 위해 추가했던 설정들을 삭제하고 kafka를 restart 해준다. 버전 업그레이드 이전에 producer를 이용해 레코드를 넣어놓고 버전 업그레이드 후에 consume이 제대로 되는지 확인해보자. 

업그레이드를 하려고 한다면 사용량이 적은 시간대를 골라 하는 것이 좋다. 브로커를 종료하게 되면 내부적으로 여러 동작들을 하기 때문이다. 부하가 높은 상태라면 시간이 다소 지연될 것이다. 따라서 사용량이 적은 시간대에 업그레이드 작업을 수행하는 것이 권장된다. 그리고 프로듀서의 ack=1 옵션을 사용하는 경우 카프카의 롤링 재시작으로 인해 일부 메세지가 손실될 수 있다.  

<br/>

## 카프카의 확장

카프카 클러스터에 브로커를 추가하거나 삭제하면 파티션 정보가 알아서 리밸런싱 된다(책에서는 안되고 수동으로 해야한다고 나오는데 자동으로 되는 것을 확인함).  

수동으로 할 수도 있는데 이때에는 ``kafka-reassign-partitions.sh`` 을 사용해서 진행한다.  

파티션 분산 배치는 단순히 이동하는 것이 아니라 브로커 내부적으로 리플리케이션하는 동작이 일어나기 때문에 파티션과 리플리케이션 팩터가 높다면 브로커에게 과중한 부하를 줄 수 있기 때문에 사용량이 낮은 시간을 이용해 파티션 재배치 작업을 수행해야 한다.  

만약 토픽 보관 주기가 기본값인 1주일인데 만약 해당 토픽의 메세지들을 모든 컨슈머가 최근의 내용까지 모두 컨슘했고, 앞으로 재처리 할 일이 없다면 삭제되어도 될 것이다. 따라서 보관 주기를 1일로 변경하고 진행하면 브로커의 부하와 네트워크 사용량을 줄일 수 있다.  

그리고 모든 토픽을 한 번에 진행하는 것이 아니라 토픽 1개씩 서서히 진행하는 방법도 있다.  

---

