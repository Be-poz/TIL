# 카프카 기본 개념과 구조

* 주키퍼: 아파치 프로젝트 애플리케이션 이름, 카프카의 메타데이터 관리 및 브로커의 정상상태 점검을 담당

* 카프카, 카프카 클러스터: 아파치 프로젝트 애플리케이션 이름, 여러 대의 브로커를 구성한 클러스터를 의미
* 브로커: 카프카 애플리케이션이 설치된 서버 또는 노드
* 프로듀서: 카프카로 메세지를 보내는 역할을 하는 클라이언트를 총칭
* 컨슈머: 카프카에서 메세지를 꺼내가는 역할을 하는 클라이언트를 총칭
* 토픽: 카프카는 메세지 피드들을 토픽으로 구분하고, 각 토픽의 이름은 카프카 내에서 고유함
* 파티션: 병렬 처리 및 고성능을 얻기 위해 하나의 토픽을 여러 개로 나눈 것을 말함
* 세그먼트: 프로듀서가 전송한 실제 메시지가 브로커의 로컬 디스크에 저장되는 파일ㅇ르 말함
* 메시지 또는 레코드: 프로듀서가 브로커로 전송하거나 컨슈머가 읽어가는 데이터 조각을 말함



### 레플리케이션

카프카에서 레플리케이션이란 각 메시지들을 여러 개로 복제해서 카프카 클러스터 내 브로커들에 분산시키는 동작을 의미한다. 이러한 리플리케이션 동작 덕분에 하나의 브로커가 종료되더라도 카프카는 안정성을 유지할 수 있다.  

replication-factor: 카프카 내 몇 개의 리플리케이션을 유지하겠다는 의미  

리플리케이션 팩터 수가 커지면 안정성은 높아지지만 그만큼 브로커 리소스를 많이 사용하게 된다. 따라서 복제에 대한 오버헤드를 줄여서 최대한 브로커를 효율적으로 사용하는 것을 권장한다. 기준을 세워두고 리플리케이션 팩터 수를 설정해야한다.  

* 테스트나 개발 환경: 리플리케이션 팩터 수를 1로 설정
* 운영 환경(로그성 메시지로서 약간의 유실 허용): 레플리케이션 팩터 수를 2로 설정
* 운영 환경(유실 허용하지 않음): 리플리케이션 팩터 수를 3으로 설정



### 파티션

하나의 토픽이 한 번에 처리할 수 있는 한계를 높이기 위해 토픽 하나를 여러 개로 나눠 병렬 처리가 가능하게 만든 것을 파티션이라고 한다. 하나를 여러 개로 나누면 분산 처리도 가능하다. 나뉜 파티션 수만큼 컨슈머를 연결할 수 있다.  

파티션 번호는 0부터 시작한다.  

**파티션 수는 초기 생성 후 언제든지 늘릴 수 있지만, 반대로 한 번 늘린 파티션 수는 절대로 줄일 수 없다는 점을 반드시 명심**  

파티션은 브로커한테 분배된다. 만약 6개의 파티션으로 토픽을 생성하고 3대의 브로커가 있다면 2개씩 토픽이 분배된다. 만약 브로커의 숫자보다 낮거나 파티션/브로커의 값이 딱 떨이지지 않는 경우에는 브로커마다 가지고 있는 파티션의 수가 달라질 수 있다.  

브로커 서버의 ``/data/kafka-logs`` 를 확인해보면 토픽의 파티션별 디렉토리가 생기는데 이것으로 확인가능하다.  



### 세그먼트

프로듀서에 의해 브로커로 전송된 메시지는 토픽의 파티션에 저장되며, 각 메시지들은 세그먼트라는 로그 파일의 형태로 브로커의 로컬 디스크에 저장된다.  

파티션이 1개인 a라는 토픽을 예로 들어 정리하자면,  

1. 프로듀서는 카프카의 a 토픽으로 메시지를 전송
2. 메시지를 받은 a 토픽은 파티션이 하나뿐이므로, 프로듀서로부터 받은 메시지를 파티션n의 세그먼트 로그 파일에 저장
3. 브로커의 세그먼트 로그 파일에 저장된 메시지는 컨슈머가 읽어갈 수 있음

<br/>

## 카프카의 핵심 개념

### 분산 시스템

분산 시스템으로 인하여 성능이 높고 하나의 서버 또는 노드 등에 장애가 발생해도 다른 서버 또는 노드가 대신 처리하므로 장애 대응이 탁월하며, 부하가 높은 경우에는 시스템 확장이 용이하다. 리소스가 한계치에 도달하면 단순히 브로커를 추가하는 방식으로 확장이 가능하다. 카프카에서 브로커는 온라인 상태에서 매우 간단하게 추가할 수 있다.  

### 페이지 캐시

카프카는 높은 처리량을 얻기 위해 몇 가지 기능을 추가했는데, 그중 대표적인 것이 바로 페이지 캐시의 이용이다.  
페이지 캐시는 직접 디스크에 읽고 쓰는 대신 물리 메모리 중 애플리케이션이 사용하지 않는 일부 잔여 메모리를 활용한다.  

### 배치 전송 처리

카프카는 수많은 메세지들을 주고받기 때문에 단건이 아닌 수많은 통신을 묶어서 처리할 수 있게끔 배치 전송을 지원한다.  

### 압축 전송

카프카는 메세지 전송 시 압축 전송을 사용하는 것을 권장한다. 지원하는 압축 타입은 gzip, snappy, lz4, zstd 등이다.  
배치 전송과 같이 사용되면 좋은데 파일 하나를 압축하는 것보다 비슷한 파일 10개 혹은 20개를 압축하는 쪽의 압축 효율이 더욱 좋기 때문이다.  

높은 압축률이 필요한 경우라면 gzip, zstd를 권장하고, 빠른 응답 속도가 필요하다면 lz4, snappy를 권장한다.  

### 토픽, 파티션, 오프셋

카프카는 토픽이라는 곳에 데이터를 저장하고, 토픽은 병렬 처리를 위해 여러 개의 파티션이라는 단위로 다시 나뉜다.  
이 파티션의 메세지가 저장되는 위치를 오프셋이라고 부른다. 

### 고가용성 보장

고가용성을 보장하기 위해 카프카에서는 리플리케이션 기능을 제공한다. 리플리케이션 기능은 토픽 자체를 복제하는 것이 아니라 토픽의 파티션을 복제하는 것이다.  

원본과 리플리케이션을 구분하기 위해 흔히 마스터, 미러 같은 용어를 사용하는데 카프카에서는 리더와 팔로워라고 부른다.  

팔로워가 많다고 좋은 것은 아닌게 브로커의 디스크 공간이 소비되기 때문에 적절한 값이 맞다.  

### 주키퍼의 의존성

주키퍼는 여러 대의 서버를 클러스터로 구성하고, 살아 있는 노드 수가 과반수 이상 유지된다면 지속적인 서비스가 가능한 구조이다. 따라서 주키퍼는 반드싀 홀수로 구성되어야 한다.  

<br/>

### 프로듀서 디자인

<img width="826" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/3f234733-46af-4d51-9a42-87edf7fceb90">

ProducerRecord는 카프카로 전송하기 위한 실제 데이터이며, 레코드는 토픽, 파티션, 키, 밸류로 구성된다.  
토픽과 밸류는 필숫값이며, 특정 파티션을 지정하기 위한 레코드의 파티션과 특정 파티션에 레코드들을 정렬하기 위한 레코드의 키는 필숫값이 아닌 선택사항이다.  

프로듀서의 send() 메서드를 통해 시리얼라이저와파티셔너를 거치게 된다. 파티션이 지정되어 있다면 파티셔너는 아무 동작도 하지 않는다. 만약 지저오디지 않은 경우라면 기본적으로 라운드로빈 방식으로 동작한다.  

전송이 실패하면 지정된 횟수만큼의 재시도 동작이 이루어지고 실패하면 최종 실패를 전달하고 성공하면 메타데이터를 리턴하게 된다.  

### 프로듀서의 주요 옵션

* bootstrap.servers: 클라이언트가 카프카 클러스터에 처음 연결하기 위한 호스트와 포트 정보
* acks: 프로듀서가 카프카 토픽의 리더 측에 메세지를 전송한 후 요청을 완료하기를 결정하는 옵션, 0,1,all이 있으며 0은 빠른 전송을 의미하지만 일부 메세지가 손실됨, 1은 리더가 메세지를 받았는지 확인하지만, 모든 팔로워를 전부 확인하지는 않음, all은 팔로워가 메세지를 받았는지 여부를 확인
* compression.type: 프로듀서가 메세지 전송 시 선택할 수 있는 압축 타입, none / gzip / snappy / lz4 / zstd 중 선택
* enable.idempotence: 설정을 true로 하는 경우 중복 없는 전송이 가능, 동시에 max.in.flight.requests.per.connection은 5 이하, retries는 0 이상, acks는 all로 설정
* max.in.flight.requests.per.connection: 하나의 커넥션에서 프로듀서가 최대한 ACK 없이 전송할 수 있는 요청 수, 메세지의 순서가 중요하다면 1로 설정할 것을 권장하지만 성능은 다소 떨어짐
* retries: 일시적인 오류로 인해 전송에 실패한 데이터를 다시 보내는 횟수
* batch.size: 배치 크기
* linger.ms: 배치 형태의 메세지를 보내기 전에 추가적인 메세지를 위해 기다리는 시간, 배치 크기에 도달하지 못해도 해당 시간에 도달하면 보내짐
* transaction.id: '정확히 한 번 전송'을 위해 사용되는 옵션이며 TransactionalId에 한해 정확히 한 번을 보장함, 사용 전 enable.idempotence를 true로 설정해야함

<br/>

### 컨슈머의 기본 동작

프로듀서가 카프카의 토픽으로 메세지를 전송하면 해당 메세지들은 브로커들의 로컬 디스크에 저장된다. 그리고 컨슈머를 이용해 토픽에 저장된 메세지를 가져올 수 있다. 컨슈머 그룹은 하나 이상의 컨슈머들이 모여 있는 그룹을 의미하고, 컨슈머는 반드시 컨슈머 그룹에 속하게 된다. 이 컨슈머 그룹은 각 파티션의 리더에게 카프카 토픽에 저장된 메세지를 가져오기 위한 요청을 보낸다.  

이때 파티션 수와 컨슈머 수는 일대일로 매핑되는 것이 이상적이다. 파티션 수보다 컨슈머 수를 높인다고해서 빠르게 컨슘되는 것은 아니고 많은 컨슈머들이 대기 상태로만 존재하게 된다. 

## 컨슈머의 주요 옵션

* bootstrap.servers: 클라이언트가 카프카 클러스터에 처음 연결하기 위한 호스트와 포트 정보
* fetch.min.bytes: 한 번에 가져올 수 있는 최소 데이터 크기, 만약 지정한 크기보다 작은 경우, 요청에 응답하지 않고 데이터가 누적될 때까지 기다린다
* group.id: 컨슈머가 속한 컨슈머 그룹을 식별하는 식별자
* heartbeat.interval.ms: 하트비트가 있으면 컨슈머의 상태가 active라는 것을 의미함, session.timeout.ms와 밀접한 관계가 있고 더 낮은 값으로 설정해야 한다. 일반적으로 session.timeout.ms의 1/3로 설정한다.
* max.partition.fetch.bytes: 파티션당 가져올 수 있는 최대 크기
* session.timeout.ms: 이 시간을 이용해 컨슈머가 종료될 것인지를 판단한다, 컨슈머는 주기적으로 하트비트를 보내야 하고, 만약 이 시간 전까지 하트비트를 보내지 않았다면 해당 컨슈머는 종료된 것으로 간주하고 컨슈머 그룹에서 제외하고 리밸런싱을 시작한다.
* enable.auto.commit: 백그라운드로 주기적으로 오프셋을 커밋한다.
* auto.offset.reset: 카프카에서 초기 오프셋이 없거나 현재 오프셋이 더 이상 존재 하지 않는 경우에 reset하는 정책
  * earliest: 가장 초기의 오프셋값으로 설정
  * latest: 가장 마지막의 오프셋값으로 설정
  * none: 이전 오프셋값을 찾지 못하면 에러를 나타냄
* fetch.max.bytes: 한 번의 가져오기 요청으로 가져올 수 있는 최대 크기
* group.instance.id: 컨슈머의 고유한 식별자이며 설정 시 static 멤버로 간주되어, 불필요한 리밸런싱을 하지 않음
* isolation.level: 트랜잭션 컨슈머에서 사용되는 옵션으로, read_uncommitted는 기본값으로 모든 메세지를 읽고, read_committed는 트랜잭션이 완료된 메세지만 읽음
* max.poll.records: 한 번의 poll() 요청으로 가져오는 최대 메세지 수
* partition.assignment.strategy: 파티션 할당 전략이며, 기본값은 range
* fetch.max.wait.ms: fetch.min.bytes에 의해 설정된 데이터보다 적은 경우 요청에 대한 응답을 기다리는 최대 시간
