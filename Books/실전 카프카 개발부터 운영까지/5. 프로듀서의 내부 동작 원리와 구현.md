# 프로듀서의 내부 동작 원리와 구현

## 파티셔너

메세지를 토픽의 어떤 파티션에 보낼지 결정하는 것이 **파티셔너**다. 기본적으로 메세지의 키를 해시 처리해서 파티션을 구하는데 파티션이 확장되는 경우 확장 이전에 특정 키가 들어가는 파티션의 번호와 확장 이후의 파티션의 번호가 달라질 수 있기 때문에 해시 방식을 이용할 때에는 파티션 수를 변경하지 않는 것이 권장된다.  

### 라운드 로빈 전략

<img width="957" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/7a7ad1cc-8880-483e-b858-cc6d2aaa47f2">

키 값이 null 일 때 라운드 로빈 방식이 사용된다.  

파티셔너를 거친 후의 레코드들은 배치 처리를 위해 프로듀서의 버퍼 메모리 영역에서 잠시 대기한 후 카프카로 전송된다.  
이때 라운드 로빈 전략은 효율을 떨어뜨릴 수 있다.  

위의 그림과 같이 각 파티션 별로 배치 전송을 위해 필요한 레코드 수가 3이라고 하자, 이 때 레코드 7부터 각 파티션당 배치 전송을 위해 필요한 레코드 수를 충족하게 될 것이다. 그 이전까지는 계속 대기하게 된다.  

물론 옵션에다가 특정 시간 초과 시 레코드를 전송하도록 설정할 수 있지만 그림에서 파티션2와 같은 경우 압축의 효과를 얻지 못한 채 레코드 하나만 보내게 되므로 비효율 적이다.  

### 스티키 파티셔닝 전략

<img width="964" alt="image" src="https://github.com/Be-poz/TIL/assets/45073750/d2059714-14bf-41ea-a820-928e13fb0cbe">

카프카 2.4 버전 부터는 하나의 파티션에 레코드 수를 먼저 채워 카프카로 빠르게 배치 전송하는 **스티키 파티셔닝 전략**을 사용한다. 동작 방식이 아주 살짝 바뀌긴 했지만 굉장히 효율적이다. 컨플루언트에 따르면 30% 이상 지연시간이 감소하고 프로듀서의 CPU 사용률도 줄어들었다고 한다.  

책에서는 키 값이 null일 때 라운드 로빈의 비효율을 개선하기 위한 전략으로 나오는데, 키 값이 존재할 때 스티키 파티셔닝 전략을 사용해서 특정 메세지 키인 경우 특정 파티션에 붙게끔 하는 방법의 전략으로도 존재하는 것 같다.  

https://www.confluent.io/ko-kr/blog/apache-kafka-producer-improvements-sticky-partitioner/

여기 글을 보면 key 값이 null 일 경우, 2.3 버전 이전에는 라운드 로빈 방식이 default 동작 방식이고 2.4 이후에는 스티키 파티셔닝 방식이 default 동작 방식이라고 나온다. key 값이 존재할 때에는 버전 관계없이 해싱 방식이 default인 것 같다.

<Br/>

## 프로듀서의 배치

프로듀서는 처리량을 높이기 위해 배치 전송을 권장하고 카프카로 전송하기 전, 배치 전송을 위해 토픽의 파티션별로 레코드들을 잠시 보관한다.  

* buffer.memory: 카프카로 메세지들을 전송하기 위해 담아두는 프로듀서의 버퍼 메모리 옵션, 기본값은 32MB
* batch.size: 배치 전송을 위해 메세지들을 묶는 단위, 기본 값은 16KB
* linger.ms: 배치 전송을 위해 버퍼 메모리에서 대기하는 메세지들의 최대 대기시간, 기본값은 0이며 배치 전송을 위해 기다리지 않고 즉시 전송된다.

스티키 파티셔닝 전략 설명 사진을 보면 점선에 buffer.memory가 적혀져있고 batch.size는 파티션 내부에 쓰여져있다.  
즉 buffer.memory는 모든 batch.size의 합보다 커야 한다. 만약 3개의 파티션이고 batch.size가 16KB라면 buffer.memory의 최소 크기는 16KB * 3 이 되어야한다. 이 값들은 정답은 없으며 조금씩 변경하면서 사용자의 환경에 맞는 값을 찾아야 한다.  

카프카로 전송 시 gzip, snappy, lz4, zsrd 등의 압축 포맷을 지원한다.  

<br/>

## 중복 없는 전송

메세지가 중복되지 않는다면 데이터 프로세싱 과정에서 중복 처리 과정을 거치지 않아도 되므로 편리하다. 그리고 일부 서비스에서는 중복이 처리된다면 치명적인 상황이 발생할 수도 있을 것이다.  

메세지 시스템들의 메세지 전송 방식에는 **'적어도 한 번 전송', '최대 한 번 전송', '정확히 한 번 전송'**이 있다.  

### 적어도 한 번 전송

프로듀서가 브로커한테 메세지를 보내고 ACK를 받는 과정에서 브로커 장애가 발생하여 ACK를 받지 못했다면 다시 한 번 메세지를 보내게 된다. 브로커가 정말 메세지를 받지 못한 상황이었더라면 성공적으로 메세지를 다시 받게되었을 것이고, 만약 메세지는 저장했는데 ACK만 전송하지 못했던 경우라면 중복 메세지가 남게될 것이다. 최소한 하나의 메세지는 반드시 보장한다는 것이 적어도 한 번 전송 방식이며, 카프카의 기본 동작 방식이다.  

### 최대 한 번 전송

최대 한 번 전송은 ACK를 받지 못하더라도 재전송을 하지 않는다. 일부 메세지가 손실되더라도 높은 처리량을 필요로 하는 대량의 로그 수집이나 IoT 같은 환경에서 사용된다고 한다.  

### 중복 없는 전송

중복 없는 전송은 프로듀서가 브로커에 메세지를 보낼 때에 PID(Producer ID)와 메세지 번호를 헤더에 포함해 함께 전송한다.  
여기서 말하는 메세지 번호는 이전 메세지에 대한 ACK를 받으면 값을 증가시킨다.  
브로커가 장애가 나서 ACK가 돌아오지 않았다면 프로듀서는 메세지를 다시 보낸다. 적어도 한 번 전송과 과정은 동일하다. 하지만 메세지를 다시 받은 브로커가 메세지의 헤더에서 PID와 메세지 번호를 확인해서 브로커에 저장되어 있다면 중복 저장하지 않고 ACK만 보낸다. 이렇게 중복을 피할 수 있다.  

메세지 번호를 시퀀스 번호라고도 한다. PID는 사용자가 별도로 생성하는 것이 아니고 프로듀서에 의해 자동 생성된다.  
또한 사용자에게 따로 노출되지 않는다.  

PID와 시퀀스 번호 정보는 브로커의 메모리에 유지되고, 리플리케이션 로그에도 저장된다.  

오버헤드가 크게 높지 않다. 컨플루언트에 따르면 중복 없는 전송을 적용한 후 기존 대비 최대 약 20% 정도만 성능이 감소했다고 한다.  

* enable.idempotence: 프로듀서가 중복 없는 전송을 허용할지 결정하는 옵션, 기본값은 false이므로 사용을 하려면 true로 해야한다. 값을 true로 하면 아래의 설정들도 모두 설정해야 한다.
* max.in.flight.requests.per.connection: ACK를 받지 않은 상태에서 하나의 커넥션에서 보낼 수 있는 최대 요청 수, 기본값은 5이며, 5 이하로 설정해야 한다.
* acks: 프로듀서 acks와 관련된 옵션이고 기본값은 1이다. all로 설정해야 한다.
* retries: ACK를 받지 못한 경우 재시도를 해야 하므로 0보다 큰 값으로 설정해야 한다.



``/data/kafka-logs``에서 토픽의 snapshot 파일을 살펴보면 PID와 시퀀스 번호가 기록되어있는 것을 확인할 수 있다.

<Br/>

## 정확히 한 번 전송

중복 없는 전송 방식이 정확히 한 번 전송한다는 의미가 아니다. 은행과 같은 경우에서는 정확히 한 번 처리하는 기능이 필요할 것이다.  

카프카에서 정확히 한 번 전송은 트랜잭션과 같은 전체적인 프로세스 처리를 의미하며, 중복 없는 전송은 정확히 한 번 전송의 일부 기능이라 할 수 있다.  

전체적인 프로세스를 관리하기 위해 카프카에서는 정확히 한 번 처리를 담당하는 별도의 프로세스가 있는데 이를 트랜잭션 API라고 부른다.  

### 디자인

프로듀서가 카프카로 정확히 한 번 방식으로 메세지를 전송할 때, 프로듀서가 보내는 메세지들은 원자적으로 처리되어 전송에 성공하거나 실패한다. 전송을 위해 트랜잭션 코디네이터가 존재하며 프로듀서에 의해 전송된 메세지를 관리하고, 커밋 또는 중단 등을 표시한다. 카프카에서는 컨슈머 오프셋 관리를 위해 오프셋 정보를 카프카의 내부 토픽에 저장하는데, 트랜잭션도 동일하게 트랜잭션 로그를 카프카의 내부 토픽인 ``__transaction_state``에 저장한다. 이 또한 카프카의 내부 토픽이므로 파티션 수와 리플리케이션 팩터 수가 존재하며 기본 값은 아래와 같다.  

* transaction.state.log.num.partitions=50
* transaction.state.log.replication.factor=3

프로듀서가 해당 토픽에 트랜잭션 로그를 직접 기록하는 것이 아니라, 프로듀서는 트랜잭션 관련 정보를 트랜잭션 코디네이터에게 알리고, 모든 정보의 로그는 트랜잭션 코디네이터가 직접 기록한다.  

이 전송을 이용해 전송된 메세지들이 카프카에 저장되면, 카프카의 메세지를 다루는 클라이언트들은 해당 메세지들이 정상적으로 커밋된 것인지 또는 실패한 것인지 식별할 수 있어야 한다. 카프카에서는 이를 식별하기 위한 정보로서, 컨트롤 메세지라고 불리는 특별한 타입의 메세지가 추가로 사용된다.  

컨트롤 메세지는 페이로드에 애플리케이션 데이터를 포함하지 않으며, 애플리케이션에게 노출되지 않는다.  
컨트롤 메세지는 오직 브로커와 클라이언트 통신에서만 사용된다.  

```java
//프로듀서 트랜잭션 초기화
producer.initTransaction();

//프로듀서 트랜잭션 시작
producer.beginTransaction();

//프로듀서 트랜잭션 중단
producer.abortTransaction();

//프로듀서 트랜잭션 커밋
producer.commitTransaction();
```

### 단계별 동작

#### 1. 트랜잭션 코디네이터 찾기

정확히 한 번 전송을 위해서는 트랜잭션 API를 이용한다. 따라서 가장 먼저 수행하는 작업은 트랜잭션 코디네이터 찾기다.  
프로듀서는 브로커에게 ``FindCoordinatorRequest``를 보내서 코디네이터 위치를 찾는다. 컨슈머 코디네이터와 유사한 역할을 하는 트랜잭션 코디네이터는 브로커에 위치한다. 트랜잭션 코디네이터의 주 역할은 PID와 transactional.id를 매핑하고 해당 트랜잭션 전체를 관리하는 것이다. 만약 코디네이터가 존재하지 않는다면 신규 트랜잭션 코디네이터가 생성된다.  

``__transaction_state`` 토픽의 파티션 번호는 transactional.id를 기반으로 해시하여 결정되고, 이 파티션의 리더가 있는 브로커가 트랜잭션 코디네이터의 브로커로 최종 선정된다. 이는 transactional.id가 정확히 하나의 코디네이터만 갖고 있다는 의미와도 같다.  

#### 2. 프로듀서 초기화

프로듀서는 ``initTransactions()`` 메서드를 이용해 트랜잭션 전송을 위한 ``InitPidRequest``를 트랜잭션 코디네이터로 보낸다. 이떄 TID(transactional.id)가 설정된 경우에는 request와 함께 TID가 트랜잭션 코디네이터에게 전송된다. 코디네이터는 TID, PID를 매핑하고 해당 정보를 트랜잭션 로그에 기록한다. 그리고 PID 에포크를 한 단계 올리는 동작을 하게 되고, PID 에포크가 올라감에 따라 이전의 동일한 PID와 이전 에포크에 대한 쓰기 요청은 무시된다.  

#### 3. 트랜잭션 시작

프로듀서는 ``beginTransaction()`` 메서드를 이용해 새로운 트랜잭션의 시작을 알리게 된다.  
코디네이터 관점에서는 첫 번째 레코드가 전송될 때까지 트랜잭션이 시작된 것은 아니다.  

#### 4. 트랜잭션 상태 추가

코디네이터는 전체 트랜잭션을 관리한다. 프로듀서가 보내는 토픽 파티션 정보를 코디네이터가 로그에 기록한다.  
트랜잭션의 현재 상태를 ``Ongoing``으로 표시한다. 만약 트랜잭션 로그에 추가되는 첫 번째 파티션이라면, 트랜잭션 코디네이터는 해당 트랜잭션에 대한 타이머를 시작한다. 기본값으로 1분 동안 트랜잭션 상태에 대한 업데이트가 없다면, 해당 트랜잭션은 실패로 처리된다.  

#### 5. 메세지 전송

메세지를 전송할 때 PID, 에포크, 시퀀스 번호가 함꼐 포함되어 전송된다. 트랜잭션 코디네이터가 있는 브로커와 프로듀서가 전송하는 메세지를 받는 브로커가 서로 다르다.  

#### 6. 트랜잭션 종료 요청

메세지 전송을 완료한 프로듀서는 ``commitTransaction()`` 또는 ``abortTransaction()`` 메서드를 호출하고 트랜잭션이 완료됨을 코디네이터에게 알리게 된다. 코디네이터는 2단계의 커밋 과정을 시작하는데 첫 번째는 트랜잭션 로그에 해당 트랜잭션에 대한 ``PrepareCommit`` 또는 ``PrepareAbort``를 기록한다.  

#### 7. 사용자 토픽에 표시 요청

그 후 코디네이터는 트랜잭션 로그에 기록된 토픽의 파티션에 트랜잭션 커밋 표시를 기록한다. 여기서 기록하는 메세지가 바로 컨트롤 메세지다. 

#### 8. 트랜잭션 완료

코디네이터는 Committed라고 로그에 기록한다. 그리고 프로듀서에게 해당 트랜잭션이 완료됨을 알린 다음 해당 트랜잭션에 대한 처리는 마무리 된다. 트랜잭션을 이용하는 컨슈머는 read_committed 설정을 하면 트랜잭션에 성공한 메세지들만 읽을 수 있게 된다.  

---

