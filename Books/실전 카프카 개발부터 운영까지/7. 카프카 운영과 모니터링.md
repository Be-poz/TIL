## 카프카 운영과 모니터링

## 안정적인 운영을 위한 주키퍼와 카프카 구성

### 주키퍼 구성

#### 주키퍼 서버 수량

카프카가 매우 중요한 클러스터가 아니라면 주키퍼는 3대로 구성하는 것이 적합하고, 카프카의 사용량이 높거나 회사에서 매우 중요한 용도로 이용되는 경우에는 5대로 구성해 안정성을 높이는 쪽이 좋다.  

#### 주키퍼 하드웨어

주키퍼는 높은 하드웨어 리소스를 요구하지 않으므로 주키퍼의 물리적인 메모리 크기는 4~8GB로 구성하고,  
디스크는 240G 또는 480G SSD로 사용하는 것을 추천한다.  

주키퍼에서 필요로 하는 힙 메모리 크기는 일반적으로 1~2GB이며, 나머지는 OS영역 등에서 사용하게 된다. 따라서 주키퍼 서버에 과도한 물리 메모리를 장착하는 것은 오히려 메모리를 낭비하는 일이 될 수 있다.  

네트워크 카드는 1G 이더넷 카드면 된다. 주키퍼와 카프카 간에는 메타데이터 정도만을 주고받으므로 주키퍼의 네트워크 사용량도 높지 않다.  

### 카프카 구성

#### 카프카 서버 수량

카프카 클러스터는 홀수가 아니어도 된다. 안정적인 리플리케이션 팩터 수인 3인 토픽 구성을 위해 최소 3대부터가 적당하다.  

#### 카프카 하드웨어

주키퍼와 달리 카프카는 배치 및 압축을 많이 사용하기 때문에 CPU 사용률이 높다. 코어 수가 많은 CPU 구성을 권장한다.  

카프카에서 요구하는 JVM 힙 크기는 일반적으로 6GB이므로 이보다 큰 값이 필요하다. 카프카에서는 힙 크기를 제외한 나머지 물리 메모리는 모두 페이지 캐시로 이용해서 빠른 처리를 돕고 있다. 따라서 메모리 여유가 있어야 성능에 도움이 된다. 조금 타이트하게 운영한다면 최소 32GB 이상 구성하는 것을 추천한다.  

디스크는 성능이 낮아도 괜찮다.  

<Br/>

## 모니터링 시스템 구성

### 애플리케이션으로서 카프카의 로그 관리와 분석

카프카는 카프카 애플리케이션에서 발생하는 모든 로그를 브로커의 로컬 디스크에 기로갛ㄴ다.  

``/usr/local/kafka/config/log4j.properties``에서 로그레벨을 설정할 수가 있다.  

```properties
log4j.appender.stateChangeAppender=org.apache.log4j.DailyRollingFileAppender
log4j.appender.stateChangeAppender.DatePattern='.'yyyy-MM-dd-HH
log4j.appender.stateChangeAppender.File=${kafka.logs.dir}/state-change.log
log4j.appender.stateChangeAppender.layout=org.apache.log4j.PatternLayout
log4j.appender.stateChangeAppender.layout.ConversionPattern=[%d] %p %m (%c)%n
```

설정을 보면 log의 rotate 기준도 나와있다. 시간마다 로그 파일이 생성되는 것인데 ``/usr/locall/kafka/log`` path로 가보면 시간별로 ``server.log`` 가 생성된 것을 확인할 수가 있다.  

* server.log: 브로커 설정 정보와 정보성 로그 등을 기록함, 브로커를 재시작하는 경우 브로커의 옵션 정보가 기록됨
* state-change.log: 컨트롤러부터 받은 정보를 기록함
* kafka-request.log: 클라이언트로부터 받은 정보를 기록함
* log-cleaner.log: 로그 컴팩션 동작들을 기록함
* conotroller.log: 컨트롤러 관련 정보를 기록함
* kafka-authorizer.log: 인증과 관련된 정보를 기록함

### JMX를 이용한 카프카 메트릭 모니터링

JMX (Java Management eXtensions)는 자바로 만든 애플리케이션의 모니터링을 위한 도구를 제공하는 자바 API로서,  
MBean (MAnaged Bean)이라는 객체로 표현된다. 그리고 카프카 관리자는 JMX를 이용해 카프카의 주요 메트릭들을 그래프와 같은 형태로 한 눈에 확인할 수 있다.  

먼저 브로커에 JMX 포트를 오픈한 다음, JMX에서 제공하는 메트릭 정보를 관리자가  GUI 형태로 볼 수 있도록 구성해야 한다.  

``/usr/local/kafka/config/jmx`` 파일을 보면 JMX의 포트번호가 나와있고,  
``netstat -ntl | grep 9999`` 명령어를 이용하여 JMX 포트가 활성화되었는지 확인해본다.  

netstat은 네트워크 연결 및 라우팅 테이블 정보를 확인하는 명령어고 ntl 옵션은 아래와 같다.  
n: 호스트 이름 대신 IP 주소로 출력  
t: TCP 연결만을 표시  
l: 리스닝 상태인 소켓만 표시  

이제 프로메테우스를 설치한다.  

```sh
sudo docker run -d --network host -p 9090:9090 -v /etc/prometheus.yml:/etc/prometheus.yml --name prometheus prom/prometheus
```

설치하고자 하는 서버에서 docker로 띄웠다. ``--network host``는 컨테이너가 호스트와 동일한 네트워크 인터페이스를 사용하게끔 하는 것이다.  

```sh
sudo docker run -d --network host -p 3000:3000 --name grafana grafana/grafana:7.3.7
```

대시보드를 위한 grafana도 설치해주었다.  

<br/>

프로메테우스의 모니터링 방식은 푸시가 아닌 풀 방식이다. 따라서 모니터링하고자하는 대상 서버에 자신의 메트릭ㅈ ㅓㅇ보를 보여줄 수 있는 익스포터를 설치해야 한다.  

익스포터란 다양한 애플리케이션에서 수집되는 메트릭들을 프로메테우스가 인식할 수 있는 형태로 나타내는 에이전트를 말한다. 따라서 익스포터를 설치한 후 웹 브라우저를 열어 대상 서버 주소로 접근하면, 익스포터에서 보여주는 다양한 메트릭 정보를 확인할 수 있다.  

프로메테우스로 모니터링할 대상 서버와 포트 정보를 프로메테우스 환경 설정 파일에 등록하면, 프로메테우스는 주기적으로 대상 서버의 메트릭값을 가져와 자신의 데이터베이스에 저장한다.  

jmx 익스포터와 노드 익스포터를 각 브로커에 모두 설치하고 프로메테우스가 배포되어있는 서버의 prometheus.yml에 해당 정보를 기입한다.  

```properties
# prometheus config
global:
  scrape_interval:     5s
  evaluation_interval: 5s

scrape_configs:
  - job_name: 'peter-jmx-kafka'
    static_configs:
      - targets:
        - peter-kafka01.foo.bar:7071
        - peter-kafka02.foo.bar:7071
        - peter-kafka03.foo.bar:7071

  - job_name: 'peter-kafka-nodes'
    static_configs:
      - targets:
          - peter-kafka01.foo.bar:9100
          - peter-kafka02.foo.bar:9100
          - peter-kafka03.foo.bar:9100

  - job_name: 'peter-kafka-exporter'
    static_configs:
      - targets:
          - peter-kafka01.foo.bar:9308
          - peter-kafka02.foo.bar:9308
          - peter-kafka03.foo.bar:9308
```

위와 같이 말이다.  

카프카 LAG 등 카프카를 모니터링 하기 위해서는 카프카 익스포터를 설치하면된다.  

---





